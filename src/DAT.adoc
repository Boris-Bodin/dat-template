:baseDir: {docdir}
include::{baseDir}/_configuration.adoc[]

= Document d'architecture technique
:toc:
:doctitle: Document d'architecture technique
:toclevels: 3
:listeVoletsLink: liste-volets

:voletApplicativeLink: volet-applicative
:voletDeveloppementLink: volet-developpement
:voletInfrastructureLink: volet-infrastructure
:voletDimensionnementLink: volet-dimensionnement
:voletSecuriteLink: volet-securite

:glossaireLink: glossaire

:annexesALink: annexe-A
:annexesBLink: annexe-B
:annexesCLink: annexe-C

[#liste-volets]

:doctitle: Dossier d'architecture

Dernière modification : {docdate}

*Etat* : _En cours_

Ce dossier est constitué :

* d’un xref:{voletApplicativeLink}[volet applicatif] présentant le contexte général et l’architecture applicative ;
* d’un xref:{voletDeveloppementLink}[volet développement] présentant l’architecture logicielle ;
* d’un xref:{voletInfrastructureLink}[volet infrastructure] présentant les aspects d’architecture techniques ou physiques ;
* d’un xref:{voletDimensionnementLink}[volet dimensionnement] présentant les aspects liés aux performances et aux sollicitations ;
* d’un xref:{voletSecuriteLink}[volet sécurité].

Chaque volet expose les contraintes, exigences puis solutions mises en œuvre.

Le glossaire du projet est disponible xref:{glossaireLink}[ici].

[TIP]
====
À lire en priorité en fonction de votre rôle :

image:{resourcesDir}/metiers.png[à lire en priorité]
====

Ce dossier d'architecture a été réalisé à partir de https://github.com/bflorat/modele-da[ce modèle].

[#volet-applicative]
:leveloffset: +1


= Volet architecture applicative

Les autres volets du dossier sont accessibles xref:{listeVoletsLink}[d'ici].

Cette section décrit les modules applicatifs en jeu et leurs échanges.

toc::[]

== Documentation de Référence

Mentionner ici les documents d'architecture de référence (mutualisés). Ce dossier ne doit en aucun cas reprendre leur contenu sous peine de devenir rapidement obsolète et inmaintenable.

.Références documentaires
[cols="1e,1e,4e,4e"]
|===
|N°|Version|Titre/URL du document| Détail

|1|2.0.4|XX_Urba_POS.pdf|POS du SI|
|===

== Non statué

=== Points soumis à étude complémentaire

.Points soumis à étude complémentaire
[cols="1e,6e,1e,1e,1e"]
|===
|Sujet| Détail | Statut| Porteur du sujet  | Échéance

|Utilisation des services Y
|En fonction de l’avancement du projet Y, ce composant pourrait appeler les services de ce dernier ou ceux de l’ancien composant Z
|EN_ATTENTE
|Projet Y
|AVANT 2040
|===

=== Hypothèses

.Hypothèses
[cols="1e,6e"]
|====
|ID| Détail

|HA1
|Même si la décision de généralisation de l'annuaire centralisé n'est pas totalement entérinée, l’application s’appuiera dessus et non sur un annuaire local.
|====

== Contexte général

=== Objectifs

[TIP]
Décrire succinctement le projet et en rappeler les objectifs. Mettre en évidence ceux qui sont structurants pour l’architecture.

====
Exemple 1 : Cette application doit permettre la dématérialisation des factures reçues de nos fournisseurs et une consultation aisée de ces documents par les services comptables.
====
====
Exemple 2 : ce projet est la réécriture en technologies Web de l’application Cobol X. Elle doit en faciliter la maintenance.
====
====
Exemple 3: l’ application X est l’un des composants principaux du programme Y. Il s’adosse sur les référentiels Personne et Facturation pour enrichir le CMS en données clients temps réel.
====

=== Existant

[TIP]
Si ce document présente un projet de refonte ou migration, décrire a minima l'application existante. Ne pas reprendre la documentation, y faire simplement référence et pointer vers son éventuel dossier d'architecture. Mentionner néanmoins toute information ayant un impact fort sur la migration ou la conception du nouveau projet.
====
Exemple 1 : L'application VENIR2 est une application Client-Server en FORMS 4 pointant vers une base Oracle 9i. Son dossier d'architecture est donné en [REFxyz].
====
====
Exemple 2 : L'application existante se base et alimente un annuaire LDAP pour ses autorisations. Le nouveau projet devant fonctionner un temps avec l'ancienne, il convient de prendre en compte les accès concurrents et la cohérence du LDAP pendant la période de tuilage.
====

=== Positionnement dans le SI

[TIP]
Si le SI est urbanisé, reprendre le plan d’occupation au sol et préciser le bloc concerné

=== Acteurs

==== Acteurs internes

[TIP]
On entend par ‘internes’ les acteurs appartenant à l’organisation. Il peut s’agir d'humains ou de composants applicatifs.

.Liste des acteurs internes
[cols="1e,1e,4e,4e"]
|===
|Acteur|Description|Population|Localisation

|Système de l'administration B
|fournit les données comptables des entreprises
|N/A
|Site de Berlin

|Agent
|Agent back-office
|100
|Site de Paris

|===

==== Acteurs externes

.Liste acteurs externes
[cols="e,e,e,e"]
|===
|Acteur| Description| Population| Localisation

|Client Web
|Une entreprise depuis un PC
|Max 1M
|Monde entier

|Client mobile
|Une entreprise depuis un mobile
|Max 2M
|Monde entier
|===

== Contraintes

=== Budget

TIP: Donner les contraintes budgétaires du projet
====
Exemple 1: Enveloppe globale de 1 M€
====
====
Exemple 2: Coûts d'infrastructure cloud < 20K€ / mois
====

=== Planning

TIP: Sans reprendre dans le détail les plannings du projet, donner les éléments intéressants pour l'architecture.
====
Exemple 1: MEP avant fev 2034, prérequis au programme HEAVY en mai 2034.
====

=== Urbanisation

[TIP]
====
Lister ici les contraintes relatives à l'urbanisation, ceci inclut par exemple mais pas seulement :

* Les règles applicables dans les appels entre composants (SOA)
* Les règles d'appels entre zones réseau
* Les règles concernant la localisation des données (MDM)
* Les règles concernant la propagation des mises à jours par événements (EDA)

====
====
Exemple 1 : les appels inter-services sont interdits sauf les appels de services à un service de nomenclature.
====
====
Exemple 2 : pour en assurer la fraicheur, il est interdit de répliquer les données du référentiel PERSONNE. Ce dernier devra être interrogé au besoin en synchrone.
====
====
Exemple 3 : Lors de la modification d'une commande, les zones comptabilité et facturation seront mises à jour de façon asynchrone via un événement.
====
====
Exemple 4 : tous les batchs doivent pouvoir fonctionner en concurrence des IHM sans verrouillage des ressources.
====
====
Exemple 5 : les services ne peuvent être appelés directement. Les appels se feront obligatoirement via une route exposée au niveau du bus d'entreprise qui appellera à son tour le service. Il est alors possible de contrôler, prioriser, orchestrer ou piloter les appels.
====
====
Exemple 6 : Les composants de cette application suivent l'architecture SOA telle que définie dans le document de référence X.
====
====
Exemple 7 : Les composants en zone Internet ne peuvent appeler les composants en zone Intranet pour des raisons de sécurité.
====

=== Juridique

Lister ici (sans détailler) les éventuelles contraintes juridiques liées au projet.

====
Exemple 1 : Le contrat cadre établi avec l'ESN XYZ prévoit de transférer à notre société les droits patrimoniaux du code source.
====

====
Exemple 2 : Le code du projet sera en licence libre et open source GPL V3.
====

====
Exemple 3 : Les données produites par le projet seront en licence Ouverte version 2.0.
====

====
Exemple 4 : Le CLUF du progiciel prévoit un accès aux sources des utilisateurs ayant des parts dans la société.
====

== Exigences

TIP: Donner ici les exigences d'architecture applicative pouvant s'appliquer au projet.

====
Exemple 1 (projet de migration) : Les modules legacy devront faire l'objet d'aussi peu d'adaptations que possible.
====

====
Exemple 2 : Les modules devront pouvoir s'interfacer avec le partenaire XYZ via leurs API.
====

====
Exemple 3 : Le développement devra pouvoir se faire au sein d'équipes distribuées, chacune travaillant sur des modules distincts.
====


== Architecture cible

=== Architecture applicative générale

[TIP]
====
Présenter ici l'application dans son ensemble (sans détailler ses sous-composants) en relation avec les autres applications du SI. Présenter également les macro-données échangées ou stockées.

Rappeler :

* Le type d'architecture (client-serveur, Web monolithique, SOA, micro-service…).
* Les grands flux entre les composants ou entre les applications dans le cas des monolithes.
* D'éventuelles dérogations aux règles d'architecture du SI.

Si l'application est prévue pour être implémentée en plusieurs étapes, décrire succinctement la trajectoire cible.
====


[TIP]
====

Le choix de la représentation est libre mais un diagramme C4 de System Landscape ou un diagramme de composant UML2 semble le plus adapté.

Numéroter les étapes par ordre chronologique assure une meilleure compréhension du schéma. Grouper les sous étapes par la notation x, x.y, x.y.z, …

Ne pas faire figurer les nombreux systèmes d'infrastructure (serveur SMTP, dispositif de sécurité, reverse proxy, annuaires LDAP, …) qui sont du domaine de l'architecture technique. Mentionner en revanche les éventuels bus d'entreprise qui ont un rôle applicatif (orchestration de service par exemple).
====

====
Exemple 1 : MesInfosEnLigne permet à une entreprise de récupérer par mail un document récapitulant toutes les informations dont l’administration dispose sur elle. L'administration peut compléter ses données par celles d'une autre administration.
====
====
Exemple 2 : MesInfosEnLigne est constituée de plusieurs microservices indépendants (composants IHM, batchs ou services REST)
====
====
Exemple 3 : Suite à la dérogation du DSI le 03 aout 20xx, l'IHM sera en architecture SPA (Single Page Application)
====

image:{resourcesDir}/archi-applicative-generale.svg[Diagramme architecture applicative générale]

=== Architecture applicative détaillée

[TIP]
====
Détailler ici tous les composants de l’application, leurs flux entre eux et avec les autres applications du SI.

Proposer un ou plusieurs schémas (de préférence des diagrammes C4 de type containers ou diagramme UML2 de composant).

Idéalement, le schéma tiendra sur une page A4, sera autoporteur et compréhensible par un non-technicien. Il devrait devenir l'un des artefacts documentaires les plus importants et figurer dans la war room d'un projet agile ou être imprimé par chaque développeur.

Si l'application est particulièrement complexe, faire un schéma par chaîne de liaison.

Utiliser comme ID des flux une simple séquence non signifiante (1, 2, …, n).
Les flux sont logiques et non techniques (par exemple, on peut représenter un flux HTTP direct entre deux composants alors qu'en réalité, il passe par un répartiteur de charge intermédiaire : ce niveau de détail sera donné dans la vue infrastructure).

Pour chaque flux, donner le protocole, un attribut synchrone/asynchrone, un attribut lecture/écriture/exécution et une description pour que le schéma soit auto-porteur.
====

==== Principes ayant dicté les choix

[TIP]
====
Donner ici l'intention dans la construction de l'architecture.
====
====
Exemple : nous utiliserons une approche monolithique et non micro-service par manque d'expertise.
====

==== Vision statique

[TIP]
====
Exposer les modules applicatifs dans leurs différentes zones ou domaines.
====
====
Exemple: module X, Y et Z dans le domaine GED. Modules A, B dans le domaine PERSONNE.
====

image:{resourcesDir}/archi-applicative-detaillee-statique.svg[Diagramme d'Architecture applicative détaillée (vue statique)]

==== Vision dynamique

[TIP]
====
Exposer les modules applicatifs dans leurs différentes zones ou domaines avec leurs flux applicatifs principaux.

Ne pas détailler les flux techniques (comme les flux liés à la supervision ou au clustering).

Si l'application est complexe, proposer un schéma global exposant tous les flux applicatifs puis un schéma par chaîne de liaison principale en numérotant les échanges (utiliser un diagramme de séquence ou (mieux) un Dynamic Diagram C4).
Il est possible également de détailler les chaînes de liaison par fonctionnailité principale.
====
====
Exemple:

image:{resourcesDir}/archi-applicative-detaillee-dynamique.svg[Diagramme architecture applicative détaillée (vue dynamique)]

====

=== Matrice des flux applicatifs

[TIP]
====
Lister ici les flux principaux de l'application.

Ne pas détailler les flux techniques de supervision ou liés au clustering par exemple. Mentionner le type de réseau (LAN, WAN).
====

.Exemple partiel de matrice de flux applicatifs
[cols='1e,3e,1e,1e,1e']
|====
|Source|Destination|Type de réseau|Protocole| Mode.footnote:[(L)ecture, (E)criture ou Lecture/Ecriture (LE), (A)ppel (vers un système stateless)]

|Entreprise|PC/tablette/mobile externe |WAN| ihm-miel | LE
|batch-traiter-demandes | service-compo-pdf |LAN | HTTP | A
|====

:leveloffset!:
[#volet-developpement]
:leveloffset: +1


= Volet développement

Les autres volets du dossier sont accessibles xref:{listeVoletsLink}[d'ici].

Cette section décrit le code à produire et comment l'écrire.

toc::[]
== Documentation de Référence

[TIP]
Mentionner ici les documents d'architecture de référence (mutualisés). Ce document ne doit en aucun cas reprendre leur contenu sous peine de devenir rapidement obsolète et inmaintenable.

.Références documentaires développement
[cols="1e,1e,4e,4e"]
|====
|N°|Version|Titre/URL du document|Détail

|1|1.0|https://references.modernisation.gouv.fr/rgaa-accessibilite/#menu
|RGAA

|====

== Non statué

=== Points soumis à étude complémentaire

.Points soumis à étude complémentaire
[cols="e,e,e,e,e"]
|====
|ID|Détail|Statut|Porteur du sujet  | Échéance

|ED1
|Le choix Angular ou React.JS pour le frontend est encore soumis à étude. Ceci n’impacte pas la partie back des services REST
|EN_COURS
|Equipe méthodes et outils
|AVANT 2040

|====


=== Hypothèses

.Hypothèses
[cols="1e,4e"]
|====
|ID|Détail

|HD1
|Même si ce point n’est pas encore totalement validé, l’application nécessitera un JRE 9 + pour tirer profil de librairies et frameworks Java indispensables au projet.
|====

== Contraintes

[TIP]
====
Lister ici les contraintes relatives à l'architecture logicielle, ceci inclut par exemple mais pas seulement :

* L'obligation d'utiliser un framework ou une filière technologique précise
* Les budgets maximums de licence ou de développement
* L'outillage (IDE, …)
* L'intégration continue
* Les normes et seuils de qualité de code applicables
* Les tests (taux de couverture, répartition par type de test, …)

====
====
Exemple 1 : La couverture de code devra être d'au moins 60%
====
====
Exemple 2 : Le module devra se baser sur le framework Hibernate pour la persistance et CDI pour l'injection de dépendance
====
====
Exemple 3 : l'application sera construite, testée et déployée en continu à chaque push via la plateforme Gitlab-ci
====

== Exigences non fonctionnelles

[TIP]
====
Contrairement aux contraintes qui fixaient le cadre auquel toute application devait se conformer, les exigences non fonctionnelles sont données par les porteurs du projet (MOA en général). Prévoir des interviews pour les déterminer. Si certaines exigences ne sont pas réalistes, le mentionner dans le référentiel des points à statuer.
====

=== Accessibilité

[TIP]
====
Cette application doit-elle être accessible aux non/mal voyants ? malentendants ?

Si oui, quelle niveau d’accessibilité ?
Se référer de préférence au Référentiel Général d’Accessibilité (https://references.modernisation.gouv.fr/rgaa-accessibilite/#menu[RGAA]) qui préconise un niveau WCAG 2.0 AA :

Il existe d’autres normes d’accessibilité (WCAG, AccessiWeb …) . Attention à correctement évaluer le niveau visé (ni sur-qualité, ni sous-qualité) :

* Atteindre un niveau d’accessibilité très élevé peut être coûteux et contraignant technologiquement. Il demande également de bonnes compétences (accessibilité, HTML5/CSS3 en particulier) et des profils rares.
* La loi est de plus en plus stricte pour les administrations qui doivent respecter un niveau d’accessibilité suffisant (loi  n°2005-102 du 11 février 2005 pour l’égalité des droits et des chances, la participation et la citoyenneté des personnes handicapées). « Tous les sites publics européens doivent atteindre le double A (AA) du W3C/WAI ».
====

=== Ergonomie

==== Charte ergonomique

[TIP]
====
En général, on se réfère ici à la charte ergonomique de l’organisme. Lister néanmoins d’éventuelles spécificités. Ne pas reprendre les contraintes d’accessibilité listées plus haut.
====

==== Spécificités sur les widgets

[TIP]
====
Des comportements ergonomiques très précis peuvent impacter assez fortement l’architecture et imposer une librairie de composants graphiques ou une autre. Il est fortement déconseillé de personnaliser des librairies existantes (coût de maintenance très élevé, grande complexité). Bien choisir sa librairie ou restreindre ses besoins.
====
====
Exemple 1 : les tableaux devront être triables suivant plusieurs colonnes.
====
====
Exemple 2 : de nombreux écrans seront pourvus d’accordéons
====

==== Polices de caractère

[TIP]
====
Décrire ici les polices de caractère à utiliser pour les pages Web, les applications ou les documents composés.

Le choix des polices suit des contraintes de licences. Afin d'assurer une sécurité juridique au projet, attention aux polices commerciales soumises à royalties (en particulier les polices appartenant à Microsoft comme Times New Roman, Courier, Verdana, Arial) et qui ne permettent pas de produire gratuitement des documents sans passer par leurs éditeurs (Word, …).

Voir par exemple la police https://www.gouvernement.fr/charte/charte-graphique-les-fondamentaux/la-typographie[Marianne] préconisée par le gouvernement en tant que police à chasse variable.

Redhat propose quatre familles de polices https://fr.wikipedia.org/wiki/Liberation_(police_d%27%C3%A9criture)[Liberation Mono] en licence Open Source sécurisante sur un plan juridique et compatible métriquement avec le Monotype, le Courrier New, l'Arial et le Times New Roman.
====

==== Site Web adaptatif

[TIP]
====
Lister les contraintes d’affichage multi-support. Utiliser quand c'est possible les frameworks modernes (type AngularJS ou React.js). Il existe plusieurs niveaux d’adaptation des pages Web :

* Statique (largeur de page fixe).
* Dynamique (redimensionnement automatique, les tailles sont exprimées en %).
* Adaptatif (les distances sont exprimées en unités dont la taille dépend du support).
* Responsive (le contenu et son agencement dépend du support).

WARNING: Un design responsive vient avec ses contraintes (duplication de code, augmentation du volume du site à télécharger par le client, complexité, plus de tests end-to-end à prévoir…).
====

==== Progressive Web Apps (PWA)

[TIP]
====
Spécifier si l'application est progressive. Les applications PWA sont des applications Web HTML5 possédant tous les attributs des applications natives (mode déconnecté, rapide, adaptatif, accessible depuis l'OS, …)
====
====
Exemple : L'application X sera totalement PWA. Des tests devront démonter que le site continuer à fonctionner sans réseau et que les pages se chargent en moins de 5 secs en 4G.
====

==== Navigateurs supportés

[TIP]
====
Préciser quels sont les navigateurs supportés si votre projet contient une IHM Web.

Lorsqu'on s'adresse à un public dont on ne gère pas le parc de navigateurs (comme un site Web sur Internet), la meilleure option pour rendre les choses intelligibles et expliciter les enjeux est de négocier avec les parties prenantes du projet un pourcentage de public supporté en se basant sur des https://gs.statcounter.com/[statistiques]. Par exemple : "Support de 95 % des navigateurs".
====

WARNING: Supporter d’anciens navigateur (IE en particulier) peut engendrer des surcoûts rédhibitoires et des risques sur la sécurité. Dans tous les cas, il convient d’évaluer les surcoûts de tester sur plusieurs plate-formes. Il existe de bons outils (payants) comme Litmus ou EmailOnAcid permettant de générer un rendu des sites Web et des courriels HTML sur une combinatoire d’OS / type de lecteur (PC/tablette/mobile) /navigateur très vaste (de l’ordre de 50).  Ce type de site est incontournable pour une application grand public.

====
Exemple 1 : L’application intranet X devra fonctionner sur les navigateurs qualifiés en interne (cf norme xyz)
====
====
Exemple 2 : L’application Y étant une application internet visant le public le plus large possible, y compris des terminaux de pays en voie de développement. Il devra supporter Firefox 3+, IE 8+, Opera 6+.
====
====
Exemple 3 : L’application Z vise le public le plus large et doté de systèmes raisonnablement anciens et devra donc supporter : Firefox 6+, Chrome 8+, Opera 8+, IE 10, Edge.
====

==== Internationalisation (i18n)

[TIP]
====
Préciser les contraintes de l’ application en terme d’i18n : localisation des libellés, direction du texte, mise en page adaptable, code couleur spécifique, format de dates, devises, affichage des séparateurs décimaux, etc.
====
====
Exemple 1 : L’IHM X sera traduite en 25 langues dont certaines langues asiatiques et l’arabe.
====
====
Exemple 2 : les formats de dates et autres champs de saisie devront être parfaitement localisés pour un confort maximal de l’utilisateur.
====

==== Mode déconnecté

[TIP]
====
Préciser si l'application doit pouvoir continuer à fonctionner sans accès à Internet ou au LAN (très courant pour les applications utilisées par les professionnels en déplacement par exemple).

Il peut s’agir de clients lourds classiques (Java, C, …) possédant leur base locale pouvant être synchronisée de retour au bureau. Il peut également s'agir d'applications PWA (voir plus haut) utilisant un service worker pour les resources statiques et du stockage navigateur (local storage, base de données IndexedDB).
====
====
Exemple 1 : L'application sera développée en Java Swing avec stockage local basé sur une base H2 synchronisées avec la base commune par appels REST.
====
====
Exemple 2 : L'application mobile sera en mode PWA, entièrement écrite en HTML5 avec local storage pour stocker les données de la journée dans le navigateur.
====

=== Exigences de SEO

[TIP]
====
Le SEO (Search engine optimization) concerne la visibilité d'un site Web au travers des moteurs de recherches (comme Google ou Quant).
====
====
Exemple 1 :  Aucune indexation nécessaire ni désirée (site interne)
====
====
Exemple 2 : Les pages statiques du site devront suivre les bonnes pratiques SEO pour optimiser sa visibilité.
====

=== Exigences d'écoconception

[TIP]
====
L'écoconception consiste à limiter l'impact environnemental des logiciels et matériels utilisés par l’application. Les exigences dans ce domaine s'expriment généralement en WH ou équivalent CO2.

A noter que la loi française (voir loi https://ecoresponsable.numerique.gouv.fr/publications/guide-pratique-achats-numeriques-responsables/demarche-numerique-responsable/que-prevoit-la-loi/[du n°2020-105 du 10 février 2020, ou loi AGEC]) exige de réduire le gaspillage lié au numérique, notamment concernant l'obsolescence logicielle (art. 27).

Lister ici les exigences d'écoconception portant sur les logiciels.
====
====
Exemple : La consommation électrique moyenne causée par l’affichage d'une page Web ne devra pas dépasser 10mWH, soit pour 10K utilisateurs qui affichent en moyenne 100 pages 200 J par an : 50 g/KWH x 10mWH x 100 x 10K x 200 = 100 Kg équivalent CO2 / an.
====

== Architecture cible

=== Pile logicielle

==== Filière technique retenue

[TIP]
====
Donner les technologies choisies parmi les technologies au catalogue de l’organisation. S’il existe des écarts avec le catalogue, le préciser et le justifier.
====
====
Exemple : cette application est de profil P3 : "Application Web Spring" avec utilisation exceptionnelle de la librairie JasperReport.
====
====
Exemple : Utilisation de Reacts.js à titre expérimental au sein de l'organisation. Validé en commité architecture le …
====

==== Composants logiciels

[TIP]
====
Lister ici pour chaque composant les principales librairies et frameworks utilisés ainsi que leur version. Ne pas lister les librairies fournies au runtime par les serveurs d'application ou les frameworks. Inutile de trop détailler, donner uniquement les composants structurants.
====
====
Exemple :

.Exemple de pile logicielle
[cols="1e,4e,1e"]
|====
|Librairie|Rôle|Version

|Framework Angular2
|Framework JS de présentation
|2.1.1

|JasperReport
|Editique transactionnelle, composition des factures au format PDF
|6.3.0
|====
====

=== Performances

IMPORTANT: Les exigences sont dans la link:./vue-architecture-dimensionnement.adoc[vue dimensionnement].


[TIP]
====
Même si des campagnes de performance sont prévues, l'expérience montre que la plupart des problèmes de performance auraient pu être détectés dès le développement.
Il est donc important que les développeurs profilent leur code, dès leur poste de travail (à prévoir dans le Definition Of Done du projet). Il ne sera pas possible de détecter tous les problèmes (scalabilité, concurrence, robustesse, tuning des caches, …) mais la plupart des problèmes de temps de réponse. Il est également souvent possible de simuler de la concurrence et de la charge. Nous présentons ici quelques pistes très basiques et à la portée de tout développeur.

Coté Frontend :

* Limiter la complexité des CSS (sélecteurs ou fonctions en particulier)
* Utiliser un profiler (comme celui de Chrome)
* Privilégier les appels asynchrones
* …

Coté Backend :

* S'assurer que la pagination serveur va bien jusqu'à la base de donnée (utiliser `FETCH FIRST x ROWS ONLY` mais https://www.postgresqltutorial.com/postgresql-fetch/[pas `LIMIT` and `OFFSET`]).
* Ne pas mettre en place de contraintes inutiles en base de données.
* Limiter le nombre de jointures et les relations many-to-many.
* Dans des cas de grosses volumétries, étudier les solutions de partitionnement de tables.
* Ne pas oublier d'ajouter tous les index nécessaires, utiliser l'analyse du plan d'exécution pour vérifier qu'il n'y a pas de full scans.
* Attention aux fonctions SQL qui 'cassent' les index (comme  `UPPER()`). Privilégier les traitements coté code backend si possible.
* Activer les logs de requêtes (exemple Hibernate : `org.hibernate.SQL=DEBUG`,`-Dhibernate.generate_statistics=true`) et vérifier les requêtes SQL et leur nombre (pour détecter en particulier le problème du https://stackoverflow.com/questions/97197/what-is-the-n1-selects-problem-in-orm-object-relational-mapping[SELECT N+1], très courant).
* Disposer même sur poste de travail d'un jeu de donnée minimal (une centaine d'enregistrement).
* Vérifier avec un profiler (comme JVisualVM en Java) la consommation mémoire pour détecter les fuites ou les surconsommations.
* Vérifier qu'il n'y a pas de fuite de threads ou de deadlocks en comptant le nombre de threads actifs sur une période suffisamment longue (une nuit complète par exemple).
* Stresser les API _a minima_ (avec des injecteurs comme JMeter ou K6) et via une rampe progressive.
* Traquer les IO (des millions de fois plus lents que des accès mémoire).
* …

Frontend et backend :

* Toute ressource (taille de chaîne, nombre d'appel sur une durée, …) doit systématiquement être bornée par une limite (pas d'open bar).
* Vérifier que la taille des requêtes HTTP reste en dessous de quelques dizaines de Kio (hors GET sur fichiers). Utiliser la <<Tri et Pagination,pagination cliente et serveur>>.
* Traquer le bavardage réseau : grouper les requêtes quand possible (il faut trouver un compromis avec la règle précédente). S'aider de la règle ‘I’ de SOLID (Interface Segregation).
* Prévoir des endpoints multivalués (exemple: `GET /personnes?list=id1,id2…`) pour récupérer plusieurs éléments à la fois
(doit se concrétiser par un seul `SELECT WHERE .. IN` dans la requête finale, pas une boucle dans le code !)

====

WARNING: Ne pas tomber à l'inverse dans l'optimisation prématurée "source de tous les problèmes" selon Donald Knuth. Écrire le code le plus simple possible et suivre un bon design, ne l'optimiser qu’ensuite.
N'optimiser que si cela vaut le coût (loi de Pareto). Commencer par les optimisations les plus significatives et ne pas perdre son temps à grappiller des microsecondes voire nanosecondes.


=== Spécificités d’usine logicielle

[TIP]
====
Sans reprendre le fonctionnement de la PIC (Plate-forme d’Intégration Continue) de l'organisation, préciser si ce projet nécessite une configuration particulière.
====
====
Exemple : Les jobs Jenkins produiront le logiciel sous forme de containers Docker si  tous les TU sont passants. Les tests d'intégration seront ensuite exécutés sur ce container. Si tous les tests d’intégration et BDD sont passants, l'image Docker est releasée dans Nexus.
====

=== Bonnes pratiques

[TIP]
====
Lister les bonnes pratiques (blueprints) applicables. Éviter les bonnes pratiques 'maison' mais privilégier celles qui viennent de la communauté et sont donc éprouvées et déjà connus des développeuses et développeurs. Idéalement, il ne devrait y avoir ici que les liens vers des ressources externes.
====
====
Exemple : Suivre les recommendations de https://www.restapitutorial.com/[ce tutoriel] pour la conception d'API Restful.
====

=== Normes de développement et qualimétrie

[TIP]
====
Rendre explicite les règles et le niveau de qualité requis pour le code
====
====
Exemple 1 : Les règles de qualité à utiliser pour le code seront (https://rules.sonarsource.com/java[les règles standards SonarQube pour Java]).
====
====
Exemple 2 : Le niveau de qualité exigé correspond au https://docs.sonarqube.org/6.7/QualityGates.html[Quality Gate SonarQube] recommandé :

* 80% de couverture de code minimum
* 3 % max de lignes dupliquées
* Niveau A en Maintenabily, Relability et Security
====

====
Exemple 3 : Quelle langue utilisée pour le code ? français pour les termes fonctionnels (il est impératif d'utiliser les termes métiers comme préconisé par le DDD) et l'anglais pour les termes techniques génériques.
====

=== Patterns notables

[TIP]
====
Préciser si ce projet a mis en œuvre des patterns (GoF, JEE ou autre) structurants. Inutile de reprendre les patterns déjà supportés par les langages ou les serveurs d'application (par exemple, l'IoC avec CDI dans un serveur JEE 6).
====
====
Exemple 1 : pour traiter l'explosion combinatoire des contrats possibles et éviter de multiplier les niveaux d'héritage, nous utiliserons massivement la pattern décorateur [GoF] dont voici un exemple d’utilisation : <schéma>.
====

=== Spécificités des tests

[TIP]
====
Une méthodologie ou une technologie particulière est-elle en jeu dans ce projet ? Quelle est la stratégie de tests ?
====
====
Exemple 1 : ce projet sera couvert en plus des TU et tests d’intégration car des tests d'acceptance BDD (Behavioral Driven Development) en technologie JBehave + Serenity.
====
====
Exemple 2 : ce projet sera développé en TDD (test first)
====
====

Exemple 3 : Types de tests

.Types de tests
[cols='2s,1,1,1,1,4a']
|====
|Type de test | Temps à investir | Manuel ou automatisé ? | Type de module ciblé | Taux de Couverture visée | Détail

|TU
|Très élevé
|Automatisé
|Backend et Frontend
|env. 80%
|Format BDD : spécifications de comportements des classes et méthodes

|Spécifications exécutables
|Très élevé
|Automatisé
|Api
|env. 100% pour les classes du domaine
|Mode bouchonné.

|Tests de contrats
|Faible
|Automatisé
|Liens UI/API
|env. 100% du code appelant coté UI et des contrôleurs Spring coté API
|Teste la non régression des échanges lors de l'appel des opérations des API REST (principe CDC=Consumer-Driven Contract) via les outils Pact et pact-react-consumer.

|Tests d'architecture
|Très faible
|Automatisé
|API et batchs
|N/A, 100% du code est validé par l'outil
|En particulier, ces tests simples à écrire vérifieront le respect des règles de l'architecture hexagonale. Utilisation du framework de test ArchUnit.

|TI (tests d'intégration)
|Faible
|Automatisé
|Composants appelant des systèmes externes (bases de données, API…)
|50 à 60%
|Chaque TI ne doit tester qu'un seul système externe à la fois

|E2E (tests bout en bout)
|Faible
|Automatisé
|UI
|30%, cas nominaux (happy path)
|Ecrits en CodeceptJS, Selenium ou technologie similaire. Ils seront limités à un rôle de smoke tests (détection de problèmes grossiers). Ces tests ne seront pas bouchonnés mais seront effectués sur chaîne de liaison instanciée de bout en bout. Pour éviter le travail inutile, ces tests seront faits au niveau de features entières, pas forcément à chaque sprint. Ces tests feront office également de tests système puisqu'ils solliciteront un maximum de modules débouchonnés.

|Tests de performance
|Faible (hors campagnes de performance dédiées)
|Automatisé
|API critiques
|20%
|Possiblement automatisés en CI en DEV mais également lancé manuellement par les développeurs

|Tests d'accessibilité
|Moyenne
|Automatisé + manuel
|UI
|50%
|Tests Axe-Core lancés en CI à compléter d'un audit manuel

|Tests de sécurité
|Moyenne
|Manuel
|Tous
|Faible, uniquement sur les fonctions sensibles
|Audit à prévoir

|Tests système
|Faible
|Manuels
|UI et batchs
|10%
|Tests menés par l'équipe de développement couvrant des scénarios fonctionnels complets. Le but
est ici de tester le fonctionnement de l'ensemble des modules (ce qui n'est pas automatisable) et de
détecter un maximum de bugs avant les tests d'UAT.

|Tests UAT (acceptance)
|Moyenne
|Manuels
|UI, batchs lancé à la main
|de 30% à 80% selon le nombre de scénarios prévus
|Tests menés en recette par des utilisateurs finaux sur environnement non bouchonné avec des cahiers de tests. Tests d'acceptance de bout n bout (on suit un cahier de tests avec les cas nominaux), Tests exploratoires (on tente toutes les combinatoires possibles avec un guidage minimal dans le cahier de test)
|====
====

NOTE: Pour un projet d'envergure, la stratégie de test fait en général l'objet d'un document propre. Une stratégie standard peut également être définie au niveau du SI.

=== Éco-conception

[TIP]
====
Lister ici les mesures logicielles permettant de répondre aux exigences d'écoconception listées plus haut. Les réponses à ces problématiques sont souvent les mêmes que celles aux exigences de performance (temps de réponse en particulier). Dans ce cas, y faire simplement référence. Néanmoins, les analyses et solutions d'écoconception peuvent être spécifiques à ce thème.

Quelques pistes d’amélioration énergétique du projet :

* Utiliser des profilers ou des outils de développement intégrés dans les navigateurs (comme Google Dev Tools) pour analyser la consommation de ressources (nombre, durée et taille des requêtes).
* Pour les apps, utiliser des outils de supervision de la consommation de batterie comme Battery Historian.
* Utiliser la suite d'analyse spécialisée Greenspector.
* Mesurer la consommation électrique des systèmes avec les sondes PowerAPI2 (développé par l'INRIA et l'université Lille 1).
* Mesurer la taille des images et les réduire (sans perte) avec des outils comme pngcrush, OptiPNG, pngrewrite ou ImageMagick.
* Optimiser la consommation mémoire et CPU des applications, tuner le GC pour une application Java.
* Faire du lazy loading pour le chargement des ressources occasionnelles.
* Limiter les résultats retournés de la base de donnée (pagination).
* Grouper les traitements de masse dans des batchs qui seront plus efficaces (lots).
====
====
Exemple 1 : le processus gulp de construction de l'application appliquera une réduction de taille des images via le plugin imagemin-pngcrush.
====
====
Exemple 2 : des tests de robustesse courant sur plusieurs jours seront effectués sur l’application mobile après chaque optimisation pour évaluer la consommation énergétique de l'application.
====
====
Exemple 3 : Les campagnes de performance intègreront une analyse fine de la consommation de bande passante et en cycles CPU même si les exigences en temps de réponses sont couvertes, ceci pour identifier des optimisations permettant de répondre aux exigences d'éco-conception si elles ne sont pas atteintes.
====

=== Gestion de la robustesse

==== Gestion des transactions

[TIP]
====
Lister ici les décisions prises concernant la gestion des transactions. Ceci est surtout utile pour un système distribué. Quelques exemples de problématiques :

* Autorise-t-on les mises jours sur de multiples composants lors d'une même requête ?
* Si oui, assurons nous le caractère ACID du tout (via le mode XA par exemple) ?
* Quel moteur transactionnel utilisons nous ?
* Quel niveau d'isolation transactionnelle (read commited, uncommited, repeatable read, serializable) ?
* Si aucun moniteur transactionnel n'est utilisé (appel de plusieurs services REST en mise à jour par exemple), prévoit-t-on des transactions compensatoires en cas d'échec de l'une des mises à jours ?

====
====
Exemple : nos ressources n'étant pas transactionnelles (services REST), et voulant éviter de faire des transactions compensatoires, il est interdit d'appeler deux services en mise à jour de façon synchrone. Au besoin, nous utiliserons une file pour effectuer des mises à jour au fil de l'eau.
====

==== Gestion des sessions

[TIP]
====
Comment gère-t-on les sessions HTTP permettant de fournir un contexte d'exécution à un utilisateur (exemple: son panier d'achat) ?

Notez que ceci est une surtout un problème pour les applications Web classiques dont la présentation est générée sur le serveur, pas pour les applications SPA (Single Page Application) qui gèrent toute la présentation et leur état en local dans le navigateur.

Les choix faits ici affecteront les link:vue-architecture-infrastructure[choix d'infrastructure]. Par exemple, si une session est requise et que l'infrastructure est en cluster, il faudra soit mettre en place de l'affinité de session sur les serveurs pour forcer chaque utilisateur à toujours arriver sur le même serveur disposant de ses données, soit de mettre en place un cache distribué permettant aux serveurs de partager les sessions de tous les utilisateurs (plus complexe).

Exemples de points à traiter :

* Quelles données doivent être conservées en session  ? (attention à la volumétrie, surtout si cache distribué)
* Le code doit-il être thread-safe (si le même utilisateur ouvre un autre onglet dans son navigateur par exemple) ?

====
====
Exemple : notre application JSF stockera en session HTTP uniquement son panier d'achat, pas les références produits
====

==== Gestion des erreurs

[TIP]
====
Comment gère-t-on erreurs ? Exemples de points à traiter :

* Différencions-nous erreurs fonctionnelles (erreurs fonctionnelles prévues) et techniques ? Prévoir un diagramme de classe.
* Comment logue t-on les erreurs ? quel niveau de log ?
* Où sont attrapées les exceptions ? au plus tôt ou en début d'appel de façon centralisée ?
* Utilise-t-on les exceptions standards du langage (`IOException`…) ou notre propre jeu d'exceptions ?
* La liste des erreurs est-elle consolidée ? documentée ?
* Affecte-t-on des codes erreur ?
* Affiche-on les stack-traces complètes ? si oui, coté serveur et coté client ?
* Gère-t-on les rejeux ? si oui, espace-t-on les rejeux ? de façon aléatoire (jitter) ? exponentielle (exponential backoff) ?
* Comment gère-t-on les timeouts ?
* Comment gérons-nous les rejets fonctionnels? (c.-à-d. que faire des demandes partielles ou erronées?)

====
====
Exemple : les erreurs techniques (imprévues) comme le timeout à un appel de service REST sont catchées au plus haut niveau de l'application (via un ErrorHandler). Toutes ses informations sont loguées avec la stack-trace complète mais l'appelant ne doit recupérer que le code erreur générique XYZ sans la stack-trace (pour raison de sécurité).
====

==== Gestion de la robustesse coté frontend

[TIP]
====

Tout comme le backend, le frontend requiert une robustesse importante, d'autant plus qu'il est en prise directe avec l'interface chaise-clavier.

Entre autres :

* Penser à interdire les doubles soumissions (double appel au backend si on double-clic sur un bouton). Ceci n'exclut pas de procéder à des contrôles de durcissement coté backend.

* Afin d'éviter des problèmes subtils (surtout en cas d'utilisation de stockage navigateur comme les local/session storage), penser à empêcher l'ouverture d'une même application Web dans plusieurs fenêtres ou onglets du navigateur. En cas de tentative, afficher un message d'erreur dans les fenêtres surnuméraires.

* Toujours vérifier la comptabilité du navigateur, même en environnement contrôlé. En cas de tentative d'ouverture d'une page par un navigateur non supporté, afficher un message d'erreur explicite à l'écran.
====

====
Exemple 1 : Si l'application est ouverte avec IE, un message d'erreur doit inviter l'utilisateur à utiliser un navigateur supporté.
====

====
Exemple 2 : Tous les boutons de l'application devront interdire la double soumission en désactivant temporairement les bouton sur événement.
====

=== Gestion de la configuration

[TIP]
====
Comment configure-t-on l'application ? Exemples de points à traiter :

* Quelles sont les variables incluses dans le package final de façon statique ?
* Quels sont les paramètres modifiables au runtime ?
* Mon application est-elle paramétrable via feature flags pour des raisons de canary testing par exemple ? si oui, comment je le gère dans le code ?
* Sous quelle forme les paramètres sont-ils injectés dans l'application (variable d'environnement ? fichier .properties, base de donnée, …) ?
* L'application accepte-elle une modification du paramétrage à chaud ?
* Décrire le système de configuration

====
====
Exemple (application déployées dans Kubernetes) :

La configuration sera injectée au lancement (non modifiable à chaud) via des variables d'environnements fournies dans le descripteur de déploiement Kubernetes.
====

=== Politique de gestion des branches

[TIP]
====
Quels sont des workflows de branche à prévoir ? git-flow ? TBD (Trunked-based Development) ? autre ?
====

====
Exemple :

* La politique générale adoptée est la https://trunkbaseddevelopment.com/[TBD] (Trunk-Based Development)
* La branche principale est `develop`. Il s'agit d'une branche protégée vers laquelle il n'est pas possible pousser de commits.
* Tout commit devra faire l'objet d'une Merge Request avant intégration dans `develop`. Les critères de qualité (évalués de façon automatique lors de l'intégration continue) devront être atteints pour que le commit soit intégré.
* Chaque fonctionnalité, refactoring significatif ou bugfix sera donc réalisé sur une branche topic dédiée.
* Une branche de maintenance sera tirée sur chaque tag de version x.y. Seuls les bugfixs seront mergés dans les branches de maintenance depuis `develop` via des `cherry-pick`.
====

=== Versioning

[TIP]
====
Que versionne-t-on et quel système de version utilise-t-on ?
====

====
Exemple:

* D'une façon générale, toute ressource non dérivée (source, outil, script de ci-cd, template, DDL de base de données, …) doit être versionnée.
* Les modules seront versionnés suivant la numérotation `x.y.z` (`<majeur).<évolution>.<fix>`)
* Les librairies seront versionnées suivant la même numérotation que les modules mais la valeur `x` sera incrémentée lors de toute montée de version cassant la compatibilité ascendante (principe du Semantic Versioning).
* La version logique globale du projet sera : `<lot>.<no sprint>.<déploiement>`

====

=== Gestion de la concurrence

[TIP]
====
Comment gère-t-on les accès concurrents ? Exemples de points à traiter :

* Quel scope pour les objets (si utilisation d'un moteur IoC) ?
* Les objets doivent-il être thread-safe ?
* Quelles méthodes doivent être synchronisées ?
* Risques de race condition ? de starvation ? de dead locks ?

====
====
Exemple  (Spring MVC) : Tous les controllers seront en scope singleton et ne doivent donc en aucun cas stocker d'état dans leurs attributs pour éviter des race conditions.
====

=== Encodage

[TIP]
====
Quelles sont les règles concernant l'encodage des chaînes de caractère ? Ceci est un problème récurrent dans les SI (qui n'a jamais observé d'accents corrompus sous forme de carrés ?). Ce problème est pourtant relativement simple à résoudre et n'exige que de la rigueur. Voir les exemples ci-dessous pour des exemples de dispositifs effectifs.
====

====
Exemple 1 : Le seul encodage autorisé dans tous les modules et composants techniques est l'UTF-8. L'utilisation de l'ISO-8859-1, CP-1252 ou de tout autre encodage est formellement proscrit. Ceci comprend le paramétrage des serveurs d'application (Node, Tomcat…), des sources, des fichiers de configuration, des bases de données et des fichiers.

NOTE: Dans certains cas, nous n’avons pas la main sur la lecture des  .properties (depuis un framework par exemple), il n’est alors pas possible de forcer un encodage en UTF-8.

====
====
Exemple 2 : Si un système externe impose d'envoyer ou de recevoir des chaînes de caractères dans un encodage autre que le UTF-8 (exemple : un service REST qui renvoi des données en ISO-8859-1) et qu’il n’est pas possible de modifier le contrat, il est impératif de traduire au sein d'une couche anti-corruption les chaînes de caractères et ceci au plus tôt, dès l'appel. De plus, il ne faut jamais persister dans nos systèmes une donnée dans un encodage non UTF-8.
====

=== Fuseaux horaires

[TIP]
====
Comment gère-t-on le stockage des dates ? Ceci, comme la gestion de l'encodage est un problème récurrent (décalage d'un jour, bugs lors des changements d'heure d'été/hiver, etc.) et pourtant simple à résoudre : suivre la norme https://en.wikipedia.org/wiki/ISO_8601[ISO 8601] ("Time zones in ISO 8601 are represented as local time (with the location unspecified), as UTC, or as an offset from UTC." [Wikipedia]).
====

====
Exemple 1 : Les heures ne seront jamais stockées sans fuseau horaire. En base, on utilisera des timestamps avec timezone (`timestamptz`) et en Java ou JS, des objets intégrant le fuseau horaire de façon explicite (ex: `Instant` et pas `LocalDateTime` en java) ou des epochs. La précision sera au moins de la milliseconde.
====
====
Exemple 2 : Les dates et date-heures seront stockées en base de données comme epoch millis au format entier long. Dans le cas des dates, on stockera l'epoch millis à 12:00 UTC (et pas 00:00, trop proche du jour précédent, risque de bug).
====

=== Gestion des logs

NOTE: Les aspects d'infrastructure de logs sont détaillés dans xref:{voletInfrastructureLink}#_logs[la vue infrastructure].

[TIP]
====
Donner ici les règles générales concernant les traces applicatives (logs), les niveaux et quantité de logs.
Penser à l'exploitation des logs, surtout coté serveur. Se demander s'il sera possible d'en tirer profit en cas d'erreur en production au milieu de Mio voire Gio d'autres logs et de n threads loguant en parallèle.
====

==== Règles générales

====
Exemple 1 :

* Ne pas laisser de logs de développement dans le code (exemple : `console.out("entrée dans méthode x")` ou `e.printStackTrace()`)
* Penser à utiliser des chaînes de caractère discriminantes (exemple : code erreur) pour faciliter le filtrage dans l'outil de recherche de logs.
* Toujours fournir des identifiants d'entités permettant de retrouver l'objet concerné
* Utiliser des identifiant de corrélation entre tiers (exemple : id de traitement générée coté client en JS, passée au serveur)
* Eviter les calculs coûteux (exemple: beaucoup de concaténations) et utiliser des blocs conditionnels (exemple en Java :

[source,java]
----
if (isDebugEnabled()){
   logger.debug(a+b+c)
}
----
====

==== Niveaux et quantité de logs
[TIP]
====
Expliquer quand et quoi loguer de sorte à produire des logs exploitables en production.
====

====
Exemple :

.Niveaux logs
[cols='1,3,1,1']
|====
|Niveau de gravité |Contexte d'utilisation | Volume indicatif | Environnement

|DEBUG
|En environnement de développement, il permet d'afficher les valeurs de variables, E/S de méthodes etc..
|Max quelques Mio / minute
|DEV, Recette. Interdit en PROD sauf demande expresse du projet

|INFO
|Début/fin d'un batch ou d'un appel, chargement d'une nouvelle propriété. Peut être utilisé sous forme condensée pour les appels de service (logging d'un appel et de son contexte). C'est le niveau de prolixité utilisé pour la métrologie.
|Max 10 logs / sec, quelques Kio / minute
|Tous

|WARN
|Tous les messages d'avertissement sur les informations fonctionnelles inattendues
|Pas de limites mais ne pas en abuser et y positionner un maximum de détail de contexte
|Tous

|ERROR
|Toutes les erreurs qui n'empêchent pas à l'application de fonctionner.
|Pas de limites. Positionner un maximum de détail de contexte
|Tous

|FATAL
|Toutes les erreurs bloquantes pour l'application (problème d'accès BDD, HTTP  404 ou 500). Positionner un maximum de détail de contexte. Penser à bien logger ces erreurs sur un appender console au cas où l'écriture sur FS serait impossible (disque plein). Penser que lors d'une erreur fatale, l'écriture même du log est sujette à caution (par exemple en cas de dépassement mémoire).
|Pas de limites.
|Tous
|====

====

=== Outils d'administration

[TIP]
====
L'application doit-elle fournir des services d’administration ? Il est fortement conseillé (c'est le facteur 12 des https://12factor.net/[Twelve factors d'Heroku]) d'intégrer le code d'administration directement avec le code métier.

Exemples de points à traiter :

* Dois-je fournir un moyen de purger des données, logs, caches, … ?
(on appelle quelque fois ce type de service un 'traitement interne')
* Dois-je fournir des indicateurs applicatifs de supervision ? (nombre de dossiers consultés, …) ?
* Dois-je fournir des outils de migration ?

====
====
Exemple : Le service `/interne/maj_2` effectuera une montée de version du modèle de donnée vers la V2
====

=== Tri et Pagination

[TIP]
====
Il est nécessaire de conserver une bonne fluidité de récupération des données en lot. La pagination permet de limiter le bavardage entre les clients (IHM et batchs) et les API. Décrire ici les dispositifs de pagination mis en ouvre coté client et coté serveur.
====

====
Exemple 1 (Coté serveur)

* Les requêtes en sortie de l'api sont systématiquement triées selon un ordre ascendant (le défaut) ou descendant. De plus, il sera possible de choisir le champ sur lequel se fait le tri via un autre query param.
* Afin de limiter le nombre de requêtes à destination de l'api, celle-ci retourne un nombre limité d'éléments (ce nombre sera paramétrable suivant la taille des éléments individuels). Il s'agit du query param `range` contenant le numéro de la page à récupérer + le nombre d'éléments de la page. Chaque API proposera une valeur par défaut (de l'ordre d'une centaine).
====

====
Exemple 2 (Coté client)

* Le tri doit s'appliquer sur l'ensemble des éléments en base, pas seulement sur les éléments de la dernière requête retournée par le serveur.
* Les éléments retournés seront affichés dans les tableaux par blocs (taille paramétrable d’une taille indicative de l'ordre de 20 éléments).
====

=== Provisioning et mises à jour des DDL

[TIP]
====
Décrire comment les DDL (structures de tables en base de données) et les données initiales (comme des nomenclatures) seront gérées puis mis à jour.
====

====
Exemple : Nous utiliserons Liquibase embarqué dans les war pour créer et mettre à jour les DDL de la base. Il n'y aura donc pas de scripts SQL à lancer, les requêtes nécessaires seront effectuées directement par l'application lors de son démarrage.
====

:leveloffset!:
[#volet-infrastructure]
:leveloffset: +1


= Volet infrastructure

Les autres volets du dossier sont accessibles xref:{listeVoletsLink}[d'ici].

Cette section décrit le déploiement des modules applicatifs dans leur environnement d'exécution cible et l'ensemble des dispositifs assurant leur bon fonctionnement.

toc::[]

== Documentation de Référence
[TIP]
Mentionner ici les documents d'architecture de référence (mutualisés). Ce document ne doit en aucun cas reprendre leur contenu sous peine de devenir rapidement obsolète et non maintenable.

.Références documentaires
[cols="1e,2e,5e,4e"]
|====
|N°|Version|Titre/URL du document|Détail

|1||Regles_sauvegardes.pdf
|Règles concernant les sauvegardes

|====

== Non statué
=== Points soumis à étude complémentaire
.Points soumis à étude complémentaire
[cols="1e,5e,2e,2e,2e"]
|====
|ID|Détail|Statut|Porteur du sujet | Échéance

|EI1
|Le choix technique de la solution d’API Management reste soumise à étude complémentaires
|EN_COURS
|Équipe Archi Technique
|AVANT 2040

|====

=== Hypothèses

.Hypothèses
[cols="1e,5e"]
|====
|ID|Détail

|HI1
|Nous prenons l'hypothèse que d'ici à la MEP du projet, PostgreSQL 11 sera validé en interne.
|====

== Contraintes

[TIP]
====
Les contraintes sont les limites applicables aux exigences sur le projet.

Il est intéressant de les expliciter pour obtenir des exigences réalistes. Par exemple, il ne serait pas valide d'exiger une disponibilité incompatible avec le niveau de sécurité Tier du datacenter qui l'hébergera.

====

=== Contraintes sur la disponibilité

[TIP]
====
Les éléments ici fournis pourront servir de base au SLO (Service Level Objective). Idéalement, ce dossier devrait simplement pointer sur un tel SLO sans plus de précision.

Ce chapitre a une vocation pédagogique car il rappelle la disponibilité plafond envisageable : la disponibilité finale de l’application ne pourra être qu’inférieure.
====

==== MTTD

[TIP]
====
Donner les éléments permettant d'estimer le temps moyen de détection d'incident.
====
====
Exemple 1 : l'hypervision se fait 24/7/365

Exemple 2 : le service support production est disponible durant les heures de bureau mais une astreinte est mise en place avec alerting par e-mail et SMS en 24/7 du lundi au vendredi.
====

==== Outils et normes de supervision

[TIP]
====
Donner ici les outils et normes de supervisions imposés au niveau du SI et les éventuelles contraintes liées.
====
====
Exemple 1 : L'application sera supervisée avec Zabbix

Exemple 2 : Les batchs doivent pouvoir se lancer sur un endpoint REST

Exemple 3 : un batch en erreur ne doit pas pouvoir se relancer sans un acquittement humain
====

==== MTTR

[TIP]
====
Fournir les éléments permettant d'estimer le temps moyen de réparation (Mean Time To Repair). A noter qu'il est important de distinguer le MTTD du MTTR. En effet, ce n'est pas parce qu'une panne est détectée que les compétences ou ressources nécessaires à sa correction sont disponibles.

Préciser les plages de présence des exploitants en journée et les possibilités d'astreintes.

Si vous disposez de statistiques ou de post-mortems, mentionnez les durées effectives moyennes déjà observées.

Lister ici les durées d’intervention des prestataires matériels, logiciels, électricité, télécom…

Nous subdivisons de façon indicative cette section en sous-sections "Hardware", "Système et virtualisation", "Réseau", et "Restauration de données". D'autres catégories sont possibles.
====

===== Hardware

TIP: Décrire ici les éléments permettant de prévoir le MTTR des éléments hardware (serveurs / baies / équipements réseau / systèmes électriques, etc.). Lister par exemple ici les durées d’intervention des prestataires matériels, électricité….

====
Exemple 1 : Cinq serveurs physiques de spare sont disponibles à tout moment.

Exemple 2 : Le contrat de support Hitashi prévoit une intervention sur les baies SAN en moins de 24h.

Exemple 3 : le remplacement de support matériel IBM sur les lames BladeCenter est assuré en 4h de 8h à 17h, jours ouvrés uniquement.
====

===== Système et virtualisation

TIP: Lister ici les éléments permettant d'estimer le temps de correction d'un problème lié à l'OS ou à une éventuelle solution de virtualisation.

====
Exemple 1 : Au moins un expert de chaque domaine principal (système et virtualisation, stockage, réseau) est présent durant les heures de bureau.

Exemple 2 : Comme toute application hébergée au datacenter X, l’application disposera de la présence d’exploitants de 7h à 20h jours ouvrés. Aucune astreinte n’est possible.

Exemple 3 : Le temps de restauration observé d'une sauvegarde Veeam de VM de 40 Gio est de 45 mins.

====

===== Réseau

TIP: Lister ici les éléments liés au réseau permettant d'estimer les durées d’intervention des prestataires ou fournisseurs Telecom…

====
Exemple 1 : un ingénieur réseau est d'astreinte chaque week-end.

Exemple 2 : Le SLA d'Orange prévoit un rétablissement de la connexion à Internet en conditions nominales en moins de 24H.
====

===== Restauration de données
TIP: Lister ici les éléments permettant d'évaluer la durée de restauration de données (fichiers / objets / base de données). Les exigences de RTO listées plus bas devront prendre en compte ce MTTR.

====
Exemple 1 : Le temps de restauration Barman d'une base Postgresql est d'environ (en heures) de `0.1*x + 0.2*y` avec x, la taille de la base en Gio et `y` le nombre de jours de journaux à rejouer.

Exemple 2 : La restauration d'une sauvegarde offline (sur bandes) nécessite au minimum 4H de préparation supplémentaire.
====


==== Interruptions programmées

[TIP]
====
Donner ici la liste et la durée des interruptions programmées standards dans le SI.
====

====
Exemple 1 : On estime l'interruption de chaque serveur à 5 mins par mois. Le taux de disponibilité effectif des serveurs en prenant en compte les interruptions programmées système est donc de 99.99 %.

Exemple 2 : suite aux mises à jour de sécurité de certains packages RPM (kernel, libc…), les serveurs RHEL sont redémarrés automatiquement la nuit du mercredi suivant la mise à jour. Ceci entraînera une indisponibilité de 5 mins en moyenne 4 fois par an.

====

==== Niveau de service du datacenter

[TIP]
====
Donner ici le niveau de sécurité du datacenter selon l’échelle Uptime Institute (Tier de 1 à 4).

.Niveaux Tier des datacenters (source : Wikipedia)
[cols="1,5,2,2,2,2"]
|====
|Niveau Tier|Caractéristiques|Taux de disponibilité|Indisponibilité statistique annuelle| Maintenance à chaud possible ?| Tolérance aux pannes ?

|Tier 1
|Non redondant
|99,671 %
|28,8 h
|Non
|Non

|Tier 2
|Redondance partielle
|99,749 %
|22 h
|Non
|Non

|Tier 3
|Maintenabilité
|99,982 %
|1,6 h
|Oui
|Non

|Tier 4
|Tolérance aux pannes
|99,995 %
|0,4 h
|Oui
|Oui

|====
====

====
Exemple : le datacenter de Paris est de niveau Tier III et celui de Toulouse Tier II.
====

==== Synthèse de la disponibilité plancher

[TIP]
====
En prenant en compte les éléments précédents, estimer la disponibilité plancher (maximale) d'une application (hors catastrophe). Toute exigence devra être inférieure à celle-ci. Dans le cas d'un cloud, se baser sur le SLA du fournisseur. Dans le cas d'une application hébergée en interne, prendre en compte la disponibilité du datacenter et des indisponibilité programmées.
====

====
Exemple : <disponibilité datacenter> * <plage de fonctionnement effective> * <disponibilité système > * <disponibilité hardware> = 99.8 x 99.99 x 99.6 x 99.99 =~ *99.4%*.
====

==== Gestion des catastrophes

[TIP]
====

Les catastrophes peuvent être classées en trois catégories:

* Naturelle (tremblements de terre, inondations, ouragans, canicules…).
* Incident sur l'infrastructure du datacenter (accidentel comme les accidents industriels, incendies, pannes électriques majeures, pannes majeures du réseau / stockage / serveurs, les erreurs critiques d'administrateurs ou intentionnelles: militaire, terroriste, sabotage …).
* Cyber (DDOS, virus, Ransomware … )

PRA (Plan de Reprise d'Activité) comme PCA (Plan de Continuité d'Activité) répondent à un risque de catastrophe sur le SI (catastrophe naturelle, accident industriel, incendie…). Un PRA permet de reprendre l’activité suite à une catastrophe après une certaine durée de restauration. Il exige au minium un doublement du datacenter.

Un PCA permet de poursuivre les activités critiques de l’organisation (en général dans un mode dégradé) sans interruption notable. Ce principe est réservé aux organisations assez matures car il exige des dispositifs techniques coûteux et complexes (filesystems distribués et concurrents par exemple).

Un architecte n'utilise pas les mêmes technologies suivant qu'on vise un PRA ou un PCA. Par exemple, si on vise un PCA, il faut prévoir des clusters actifs-actifs multi-zonaux (situés dans des datacenters distants géographiquement) alors que pour un PRA, l'important est la qualité et la vitesse de sauvegarde/restauration des données dans le datacenter de secours.

Note: Dans la plupart des grands comptes, PRA comme PCA impliquent une réplication par lien optique des baies SAN pour limiter le RPO au minimum et s'assurer que l'ensemble des données du datacenter soient bien répliquées. Les systèmes de sauvegarde/restauration classiques sont rarement suffisants à couvrir ce besoin. La différence est que dans le cas d'un PRA, il faut prévoir une bascule et une préparation conséquente du datacenter de secours alors que dans le cas d'un PCA, les deux (ou plus) datacenters fonctionnent en parallèle en mode actif/actif de façon nominale.

Note: La gestion des catastrophes est un sujet complexe. C'est l'un des points forts des Clouds publics (OVH, GCP, Azure, AWS…) que de gérer une partie de cette complexité pour vous. Des solutions Cloud spécifiques existent (Disaster Recovery as a Service (DRaaS)).

Décrire entre autres :

* Les matériels redondés dans le second datacenter, nombre de serveurs de spare, capacité du datacenter de secours par rapport au datacenter nominal.
* Pour un PRA, les dispositifs de restauration (OS, données, applications) prévues et le MTTR envisagé.
* Pour un PCA les dispositifs de réplication de données (synchrone ? fil de l’eau ? Combien de transactions peuvent-être perdues ?).
* Présenter la politique de failback (réversibilité) : doit-on rebasculer vers le premier datacenter ? Comment ?
* Comment sont organisés les tests de bascule à blanc ? Avec quelle fréquence ?
====
====
Exemple de PRA : Pour rappel (voir [doc xyz]), les VM sont répliquées dans le datacenter de secours via la technologie vSphere Metro Storage Cluster utilisant SRDF en mode asynchrone pour la réplication inter-baies. En cas de catastrophe, la VM répliquée sur le site de secours est à jour et prête à démarrer. Le RPO est de ~0 secs et le RTO de 30 mins.

Autre exemple de PRA (PME avec son propre datacenter à Paris) : Stockage de deux serveurs de spare dans les locaux de Lille. Sauvegarde à chaud toutes les quatre heures des données principales de l'entreprise et envoi (avec chiffrement client) sur BackBlaze.com. Le RPO est de 4h, le RTO de 2H.

Exemple de PCA avec élasticité: Les applications s’exécutent sous forme de POD Kubernetes sur au moins trois clusters situées dans des zones géographiquement distantes. Les données MongoDB sont shardées et synchronisées entre zones via un système de ReplicatSet. Le système est auto-régulé par Kubernetes et tout plantage d'un DC sera compensé en quelques secondes par la création de nouveaux POD dans les deux clusters restants. Ainsi, non seulement les utilisateurs n'auront pas de perte de disponibilité mais ils ne verront pas non plus leurs performances dégradées. Le MTTR est donc de 0.
====


=== Hébergement

* Où sera hébergée cette application ? datacenter "on premises" ? Cloud interne ? Cloud IaaS ? PaaS ? autre ?
* Qui administrera cette application ? en interne ? Sous-traité ? Pas d’administration (PaaS) … ?
====
Exemple 1: Cette application sera hébergée en interne dans le datacenter de Nantes (seul à assurer la disponibilité de service exigée) et il sera administré par l’équipe X de Lyon.
====

====
Exemple 2 : Étant donné le niveau de sécurité très élevé de l’application, la solution devra être exploitée uniquement en interne par des agents assermentés. Pour la même raison, les solutions de cloud sont exclues.
====

====
Exemple 3 : Étant donné le nombre d’appels très important de cette application vers le référentiel PERSONNE, elle sera colocalisée avec le composant PERSONNE dans le VLAN XYZ.
====

=== Contraintes réseau

[TIP]
====
Lister les contraintes liées au réseau, en particulier le débit maximum théorique et les découpages en zones de sécurité.
====
====
Exemple 1 : le LAN dispose d'un débit maximal de 10 Gbps
====
====
Exemple 2 : les composants applicatifs des applications intranet doivent se trouver dans une zone de confiance inaccessible d'Internet.
====

=== Contraintes de déploiement

[TIP]
====
Lister les contraintes liées au déploiement des applications et composants techniques.
====
====
Exemple 1 : Une VM ne doit héberger qu'une unique instance Postgresql

Exemple 2 : Les applications Java doivent être déployées sous forme de jar exécutable et non de war.

Exemple 3 : Toute application doit être packagées sous forme d'image OCI et déployable sur Kubernetes via un ensemble de manifests structurés au format Kustomize.

====

=== Contraintes de logs

[TIP]
====
Lister les contraintes liées aux logs
====
====
Exemple 1 : une application ne doit pas produire plus de 1Tio de logs / mois.

Exemple 2 : la durée de rétention maximale des logs est de 3 mois
====

=== Contraintes de sauvegardes et restaurations

[TIP]
====
Lister les contraintes liées aux sauvegardes.

Une contrainte courante est le respect de la méthode 3-2-1 :

* Au moins 3 exemplaires des données (la donnée vivante + 2 copies) ;
* Au moins 2 technologies de stockage différentes pour ces 3 copies (exemple : disque SSD pour les données vivantes et deux sauvegardes sur bande) ;
* Au moins 1 exemplaire hors-ligne et hors site (exemple : 1 jeu de bandes conservé dans un coffre ignifugé à la banque).

====
====
Exemple 1 : L'espace disque maximal pouvant être provisionné par un projet pour les backups est de 100 Tio sur HDD.

Exemple 2 : la durée de retentions maximale des sauvegardes est de deux ans

Exemple 3 : Compter 1 min / Gio pour une restauration NetBackup.
====

=== Coûts

[TIP]
====
Lister les limites budgétaires.
====
====
Exemple 1 : les frais de services Cloud AWS ne devront pas dépasser 5K€/ an pour ce projet.
====

== Exigences

[TIP]
====
Contrairement aux contraintes qui fixaient le cadre auquel toute application devait se conformer, les exigences non fonctionnelles sont données par les porteurs du projet (MOA en général).

Prévoir des interviews pour les recueillir.

Si certaines exigences ne sont pas réalistes, le mentionner dans le document des points non statués.

Les exigences liées à la disponibilité devraient être précisées via une étude de risque (type EBIOS Risk Manager)

====

=== Plages de fonctionnement

[TIP]
====
On liste ici les plages de fonctionnement principales (ne pas trop détailler, ce n’est pas un plan de production).

Penser aux utilisateurs situés dans d'autres fuseaux horaires.

Les informations données ici serviront d'entrants au SLA de l’application.
====

====
.Exemple plages de fonctionnement
[cols="1e,5e,2e"]
|====
|No plage| Heures | Détail

|1
|De 8H00-19H30 heure de Paris , 5J/7 jours ouvrés
|Ouverture Intranet aux employés de métropole

|2
|De 21h00 à 5h00 heure de Paris
|Plage batch

|3
|24 / 7 / 365
|Ouverture Internet aux usagers

|4
|De 5h30-8h30 heure de Paris, 5J/7 jours ouvrés
|Ouverture Intranet aux employés de Nouvelle Calédonie
|====
====

=== Exigences de disponibilité

[TIP]
====
Nous listons ici les exigences de disponibilité. Les mesures techniques permettant de les atteindre seront données dans l’architecture technique de la solution.

Les informations données ici serviront d'entrants au SLA de l’application.

Attention à bien cadrer ces exigences car un porteur de projet a souvent tendance à demander une disponibilité très élevée sans toujours se rendre compte des implications. Le coût et la complexité de la solution augmente exponentiellement avec le niveau de disponibilité exigé.

L’architecture physique, technique voire logicielle change complètement en fonction du besoin de disponibilité (clusters d’intergiciels voire de bases de données, redondances matériels coûteuses, architecture asynchrone, caches de session, failover …).

Ne pas oublier également les coûts d’astreinte très importants si les exigences sont très élevées. De la pédagogie et un devis permettent en général de modérer les exigences.

On estime en général que la haute disponibilité (HA) commence à deux neufs (99%), c'est à dire environ 90h d'indisponibilité par an.

Donner la disponibilité demandée par plage.

La disponibilité exigée ici devra être en cohérence avec les <<Contraintes sur la disponibilité>> du SI.
====

.Durée d’indisponibilité maximale admissible par plage
[cols="1e,5e"]
|====
|No Plage| Indisponibilité maximale

|1
|24h, maximum 7 fois par an

|2
|4h, 8 fois dans l'année

|3
|4h, 8 fois dans l'année
|====

=== Modes dégradés
[TIP]
====
Préciser les modes dégradés applicatifs envisagés.
====

====
Exemple 1 : Le site _monsite.com_ devra pouvoir continuer à accepter les commandes en l’absence du service de logistique.
====
====
Exemple 2 : Si le serveur SMTP ne fonctionne plus, les mails seront stockés en base de donnée puis soumis à nouveau suite à une opération manuelle des exploitants.
====

=== Exigences de robustesse

[TIP]
====
La robustesse du système indique sa capacité à ne pas produire d'erreurs lors d’événements exceptionnels comme une surcharge ou la panne de l'un de ses composants.

Cette robustesse s'exprime en valeur absolue par unité de temps : nombre d'erreurs (techniques) par mois, nombre de messages perdus par an…

Attention à ne pas être trop exigeant sur ce point car une grande robustesse peut impliquer la mise en place de systèmes à tolérance de panne complexes, coûteux et pouvant aller à l'encontre des capacités de montée en charge, voire même de la disponibilité.
====
====
Exemple 1 : pas plus de 0.001% de requêtes en erreur
====
====
Exemple 2 : l'utilisateur ne devra pas perdre son panier d'achat même en cas de panne
-> attention, ce type d'exigence impacte l'architecture en profondeur, voir la section <<Disponibilite>>.
====
====
Exemple 3 : le système devra pouvoir tenir une charge trois fois supérieure à la charge moyenne avec un temps de réponse de moins de 10 secondes au 95éme centile.
====

=== Exigences de RPO

[TIP]
====
La sauvegarde (ou backup) consiste à recopier les données d'une système sur un support dédié en vue d'une restauration en cas de perte. Ces données sont nécessaires au système pour fonctionner.

Donner ici le Recovery Point Objective (RPO) de l’application (en heures). Il peut être utile de restaurer suite à :

* Une perte de données matérielle (peu probable avec des systèmes de redondance).
* Une fausse manipulation d'un power-user ou d'un administrateur (assez courant).
* Un bug applicatif.
* Une destruction de donnée volontaire (attaque de type ransomware)…

====
====
Exemple : on ne doit pas pouvoir perdre plus d'une journée de données applicatives
====

=== Exigences de RTO

[TIP]
====
Le Recovery Time Objective (en heures) est l'objectif de temps maximal autorisé pour la réouverture du service suite à un incident.

Cette exigence doit être compatible (inférieure ou égale) au MTTR donné en contrainte plus haut. Il est en effet inutile d'exiger un RTO de 1H si les exploitants on mesuré un MTTR effectif de 2H. Elle doit également être compatible avec l'exigence de disponibilité.

Ne préciser cette valeur que pour expliciter un objectif de restauration précis, sinon, ne pas remplir cette rubrique et faire référence à la contrainte de MTTR plus haut.
====

====
Exemple : On doit pouvoir restaurer et remettre en ligne les 3 Tio de la base XYZ en 1h maximum.
====


=== Exigences d'archivage

[TIP]
====
L'archivage est la recopie de données importantes sur un support dédié offline en vue non pas d'une restauration comme la sauvegarde mais d'une _consultation_ occasionnelle. Les archives sont souvent exigées pour des raisons légales et conservées trente ans ou plus.

Préciser si des données de l’application doivent être conservées à long terme. Préciser les raisons de cet archivage (https://www.service-public.fr/professionnels-entreprises/vosdroits/F10029[légales] le plus souvent).

Préciser si des dispositifs spécifiques de protection de l'intégrité (pour empêcher toute modification principalement) doivent être mis en place.
====

====
Exemple 1: comme exigé par l'article L.123-22 du code de commerce, les données comptables devront être conservées au moins dix ans.
====
====
Exemple 2 : Les pièces comptables doivent être conservées en ligne (en base) au moins deux ans puis peuvent être archivées pour conservation au moins dix ans de plus. Une empreinte SHA256 sera calculée au moment de l'archivage et stockée séparément pour vérification de l'intégrité des documents en cas de besoin.
====

=== Exigences de purges

[TIP]
====

Il est crucial de prévoir des purges régulières pour éviter une dérive continue des performances et de l'utilisation disque (par exemple liée à un volume de base de données trop important).

Les purges peuvent également être imposées par la loi. Le RGPD apporte depuis 2018 de nouvelles contraintes sur le droit à l’oubli pouvant affecter la durée de rétention des informations personnelles.

Il est souvent judicieux d'attendre la MEP voire plusieurs mois d'exploitation pour déterminer précisément les durées de rétention (âge ou volume maximal par exemple) mais il convient de prévoir le principe même de l’existence de purges dès la définition de l'architecture de l’application. En effet, l'existence de purges a souvent des conséquences importantes sur le fonctionnel (exemple : s'il n'y a pas de rétention _ad vitam aeternam_ de l'historique, certains patterns à base de listes chaînées ne sont pas envisageables).
====

====
Exemple 1 : les dossiers de plus de six mois seront purgées (après archivage)
====

=== Exigences de déploiements et de mise à jour

==== Coté serveur

[TIP]
====
Préciser ici comment l’application devra être déployée coté serveur.

Par exemple :

* L'installation est-elle manuelle ? scriptées avec des outils d'IT Automation comme Ansible ou SaltStack ? via des images Docker ?
* Comment sont déployés les composants ? Sous forme de paquets ? Utilise-t-on un dépôt de paquets (type yum ou apt) ? Utilise-t-on des containeurs ?
* Comment sont appliquées les mises à jour ?
====

==== Coté client

[TIP]
====
Préciser ici comment l’application devra être déployée coté client :

* Si l’application est volumineuse (beaucoup de JS ou d’images par exemple), risque-t-on un impact sur le réseau ?
* Une mise en cache de proxy locaux est-elle à prévoir ?
* Des règles de firewall ou QoS sont-elles à prévoir ?

Coté client, pour une application Java :

* Quel version du JRE est nécessaire sur les clients ?

Coté client, pour une application client lourd :

* Quel version de l’OS est supportée ?
* Si l’OS est Windows, l’installation passe-t-elle par un outil de déploiement (Novell ZENWorks par exemple) ? l’application vient-elle avec un installeur type Nullsoft ? Affecte-t-elle le système (variables d’environnements, base de registre…) ou est-elle en mode portable (simple zip) ?
* Si l’OS est Linux, l’application doit-elle fournie en tant que paquet?
* Comment sont appliquées les mises à jour ?
====

==== Stratégie de déploiement spécifiques

[TIP]
====
* Prévoit-on un déploiement de type blue/green ?
* Prévoit-on un déploiement de type canary testing ? si oui, sur quel critère ?
* Utilise-t-on des feature flags ? si oui, sur quelles fonctionnalités ?
====

====
Exemple: L'application sera déployée sur un mode blue/green, c'est à dire complètement installée sur des machines initialement inaccessibles puis une bascule DNS permettra de pointer vers les machines disposant de la dernière version.
====

=== Exigences de gestion de la concurrence

[TIP]
====
Préciser ici les composants internes ou externes pouvant interférer avec l’application.
====
====
Exemple 1 : Tous les composants de cette application doivent pouvoir fonctionner en concurrence.En particulier, la concurrence batch/IHM doit toujours être possible car les batchs devront pouvoir tourner de jour en cas de besoin de rattrapage
====
====
Exemple 2 : le batch X ne devra être lancé que si le batch Y s’est terminé correctement sous peine de corruption de données.
====

[[exigences_ecoconception]]
=== Exigences d'écoconception

[TIP]
====
L'écoconception consiste à limiter l'impact environnemental des logiciels et matériels utilisés par l’application.Les exigences dans ce domaine s'expriment généralement en WH ou équivalent CO2.

A noter que la loi française (voir loi https://ecoresponsable.numerique.gouv.fr/publications/guide-pratique-achats-numeriques-responsables/demarche-numerique-responsable/que-prevoit-la-loi/[du n°2020-105 du 10 février 2020, ou loi AGEC]) exige de réduire le gaspillage lié au numérique, notamment concernant l'obsolescence matérielle (art. 19).

Prendre également en compte les impressions et courriers.

Selon l'ADEME (estimation 2014), les émissions équivalent CO2 d'un KWH en France continentale pour le tertiaire est de 50g/KWH.
====
====
Exemple 1 : Le Power usage effectiveness (PUE) du site devra être de 1.5 ou moins.
====
====
Exemple 2 : La consommation d'encre et de papier devra être réduite de 10% par rapport à 2020.
====

== Architecture cible

=== Principes

[TIP]
====
Quels sont les grands principes d'infrastructure de notre application ?
====
====
Exemples :

* Les composants applicatifs exposés à Internet dans une DMZ protégée derrière un pare-feu puis un reverse-proxy et sur un VLAN isolé.
* Concernant les interactions entre la DMZ et l’intranet, un pare-feu ne permet les communications que depuis l’intranet vers la DMZ
* Les clusters actifs/actifs seront exposés derrière un LVS + Keepalived avec direct routing pour le retour.
====

=== Disponibilité

[TIP]
====

La disponibilité est le pourcentage de temps minimal sur une année pendant lequel un système doit être utilisable dans des conditions acceptables. Il est exprimé en % (exemple: 99.9%).

Donner ici les dispositifs permettant d'atteindre les <<Exigences de disponibilité>>.

Les mesures permettant d’atteindre la disponibilité exigée sont très nombreuses et devront être choisies par l’architecte en fonction de leur apport et de leur coût (financier, en complexité, …).

Nous regroupons les dispositifs de disponibilité en quatre grandes catégories :

* Dispositifs de *supervision* (technique et applicative) permettant de détecter au plus tôt les pannes et donc de limiter le MTTD (temps moyen de détection).

* *Dispositifs organisationnels* :

** la présence humaine (astreintes, heures de support étendues…) qui permet d'améliorer le MTTR (temps moyen de résolution) et sans laquelle la supervision est inefficiente ;

** La qualité de la gestion des incidents (voir les bonnes pratiques ITIL), par exemple un workflow de résolution d'incident est-il prévu ? si oui, quel est sa complexité ? sa durée de mise en œuvre ? si elle nécessite par exemple plusieurs validations hiérarchiques, la présence de nombreux exploitants affecte le MTTR.

* Dispositifs de *haute disponibilité (HA)* (clusters, RAID…) qu'il ne faut pas surestimer si les dispositifs précédents sont insuffisants.

* Dispositifs de *restauration de données* : la procédure de restauration est-t-elle bien définie ? testée ? d'une durée compatible avec les exigences de disponibilité ? C'est typiquement utile dans le cas de perte de données causée par une fausse manipulation ou bug dans le code : il faut alors arrêter l'application et dans cette situation, pouvoir restaurer rapidement la dernière sauvegarde améliore grandement le MTTR.


====
[TIP]
====

*Principes de disponibilité et de redondance*:

* La *disponibilité d’un ensemble de composants en série* : `D = D1 * D2 * … * Dn`. Exemple : la disponibilité d’une application utilisant un serveur Tomcat à 98 % et une base Oracle à 99 % sera de 97.02 %.

* La *disponibilité d’un ensemble de composants en parallèle* : `D = 1 – (1-D1) * (1- D2) * ..* (1-Dn)`. Exemple : la disponibilité de trois serveurs Nginx en cluster dont chacun possède une disponibilité de 98 % est de 99.999 %.

* Il convient d'être cohérent sur la *disponibilité de chaque maillon de la chaîne de liaison* : rien ne sert d'avoir un cluster actif/actif de serveurs d'application JEE si tous ces serveurs attaquent une base de donnée localisée sur un unique serveur physique avec disques sans RAID.

* On estime un système comme hautement disponible *(HA) à partir de 99%* de disponibilité.

* On désigne par *«spare»* un dispositif (serveur, disque, carte électronique…) de rechange qui est dédié au besoin de disponibilité mais qui n'est pas activé en dehors des pannes. En fonction du niveau de disponibilité recherché, il peut être dédié à l’application ou mutualisé au niveau SI.

* Les *niveaux de redondance* d'un système (modèle NMR = N-Modular Redundancy) les plus courants sont les suivants (avec N, le nombre de dispositifs assurant un fonctionnement correct en charge) :

** *N* : aucune redondance (exemple : si l'alimentation unique d'un serveur tombe, le serveur s'arrête)

** *N+1* : un composant de rechange est disponible, on peut supporter la panne d'un matériel (exemple : on a une alimentation de spare disponible).

** *N+M*: Un seul spare n'est pas suffisant pour tenir la charge, on prévoit au moins M spares.

** *2N* : le système est entièrement redondé et peut supporter la perte de la moitié des composants (exemple : on dispose de deux alimentations actives en même temps dont chacune suffit à alimenter le serveur). Ce système est tolèrant aux pannes (Fault-tolerant).

** *2N+1*: En plus d'un système entièrement redondé, un système de secours est disponible (pour les opérations de maintenance par exemple).

====
[TIP]
====

*Clustering*:

* Un cluster est un *ensemble de nœuds (machines) hébergeant le même module applicatif*.
* En fonction du niveau de disponibilité recherché, chaque nœud peut être :

** *actif* : le nœud traite les requêtes (exemple : un serveur Apache parmi dix et derrière un répartiteur de charge). Temps de failover : nul ;

** *passif en mode «hot standby»* : le nœud est installé et démarré mais ne traite pas les requêtes (exemple: une base MySQL slave qui devient master en cas de panne de ce dernier via l'outil mysqlfailover). MTTR de l'ordre de la seconde (temps de la détection de la panne) ;

** *passif en mode «warm standby»* : le nœud est démarré et l'application est installée mais n'est pas démarrée (exemple : un serveur avec une instance Tomcat éteinte hébergeant notre application). En cas de panne, notre application est démarrée automatiquement. MTTR : de l'ordre de la minute (temps de la détection de la panne et d'activation de l'application) ;

** passif en mode «cold standby» : le nœud est un simple spare. Pour l'utiliser, il faut installer l'application et la démarrer. MTTR : de l'ordre de dizaines de minutes avec solutions de virtualisation (ex : KVM live migration) et/ou de containers (Docker) à une journée lorsqu'il faut installer/restaurer et démarrer l'application.

* On peut classer les architectures de clusters actif/actif en deux catégories :

** Les *clusters actifs/actifs à couplage faible* dans lesquels un nœud est totalement indépendant des autres, soit parce que l'applicatif est stateless (le meilleur cas), soit parce que les données de contexte (typiquement une session HTTP) sont gérées isolément par chaque nœud. Dans le dernier cas, le répartiteur de charge devra assurer une affinité de session, c'est à dire toujours router les requêtes d'un client vers le même nœud et en cas de panne de ce nœud, les utilisateurs qui y sont routés perdent leurs données de session et doivent se reconnecter. Note : Les nœuds partagent tous les mêmes données persistées en base, les données de contexte sont uniquement des données transitoires en mémoire.

** Les *clusters actifs/actifs à couplage fort* dans lesquels tous les nœuds partagent les mêmes données en mémoire. Dans cette architecture, toute donnée de contexte doit être répliquée dans tous les nœuds (ex : cache distribué de sessions HTTP répliqué avec JGroups).


====
[TIP]
====
*Failover:*

Le failover (bascule) est la capacité d'un cluster de s'assurer qu'en cas de panne, les requêtes ne sont plus envoyées vers le nœud défectueux mais vers un nœud opérationnel. Ce *processus est automatique*.

Sans failover, c'est au client de détecter la panne et de se reconfigurer pour rejouer sa requête vers un nœud actif. Dans les faits, ceci est rarement praticable et les *clusters disposent presque toujours de capacités de failover*.

Une solution de failover peut être décrite par les attributs suivants :

* Quelle *stratégie de failback* ? Par exemple: "Fail fast" (un nœud est noté comme tombé dès le premier échec); "On fail, try next one" ; "On fail, try all"…

* Quelle *solution de détection des pannes* ?

** les répartiteurs de charge utilisent des *sondes* (health check) très variées (requêtes fictives, analyse du CPU, des logs, etc.…) vers les nœuds ;

** les détections de panne des clusters actifs/passifs fonctionnent la plupart du temps par écoute des palpitations (*heartbeat*) du serveur actif par le serveur passif, par exemple via des requêtes multicast UDP dans le protocole VRRP utilisé par keepalived.

* Quel *délai de détection* de la panne ? il convient de paramétrer correctement les solutions de détection de panne (le plus court possible sans dégradation de performance).

* Quelle *pertinence de la détection* ? le serveur en panne est-il *vraiment* en panne ? un mauvais paramétrage ou une microcoupure réseau ne doit pas provoquer une indisponibilité totale d'un cluster alors que les nœuds sont sains.

* Quelle stratégie de failback ?

** dans un cluster "N-to-1", on rebasculera (failback) sur le serveur qui était tombé en panne une fois réparé et le serveur basculé redeviendra le serveur de secours ;

** dans un cluster N-to-N (architecture en voie de démocratisation avec le cloud de type PaaS comme AWS Lambda ou CaaS comme Kubernetes) : on distribue les applications du nœud en panne vers d'autres nœuds actifs (le cluster ayant été dimensionné en prévision de cette éventuelle surcharge).

* *Transparent via à vis de l’appelant* ou pas ? En général, les requêtes pointant vers un serveur dont la panne n'a pas encore été détectée tombent en erreur (en timeout la plupart du temps). Certains dispositifs ou architectures de FT (tolérance de panne) permettent de le rendre transparent pour le client.

====
[TIP]
====
Quelques mots sur les *répartiteurs de charge* :

* Un répartiteur de charge (Load Balancer = LB) est une *brique obligatoire pour un cluster actif/actif*.

* Dans le cas des clusters, une erreur classique est de créer un *SPOF* au niveau du répartiteur de charge. On va alors diminuer la disponibilité totale du système au lieu de l'améliorer. Dans la plupart des clusters à vocation de disponibilité (et pas seulement de performance), il faut redonder le répartiteur lui-même en mode actif/passif (et pas actif/actif sinon on ne fait que déplacer le problème et il faudrait un "répartiteur de répartiteurs"). Le répartiteur passif doit surveiller à fréquence élevée le répartiteur actif et le replacer dès qu'il tombe.

* Il est crucial de configurer correctement et à fréquence suffisante les tests de vie (*heathcheck*) des nœuds vers lesquels le répartiteur distribue la charge car sinon, le répartiteur va continuer à envoyer des requêtes vers des nœuds tombés ou en surcharge.

* Certains LB avancés (exemple : option redispatch de HAProxy) permettent la transparence vis à vis de l'appelant en configurant des rejeux vers d'autres nœuds en cas d'erreur ou timeout et donc d'améliorer la tolérance de panne puisqu'on évite de retourner une erreur à l'appelant pendant la période de pré-détection de la panne.

* Lisser la charge entre les nœuds et ne pas forcement se contenter de round robin. Un algorithme simple est le LC (Least Connection) permettant au répartiteur de privilégier les nœuds les moins chargés, mais il existe bien d'autres algorithmes plus ou moins complexes (systèmes de poids par nœud ou de combinaison charge + poids par exemple). Attention néanmoins à bien les tester et en maîtriser les implications pour éviter les catastrophes.

* Dans le monde Open Source, voir par exemple LVS + keepalived ou HAProxy + keepalived.

====
[TIP]
====

La *tolérance de panne* :

La tolérance de panne (FT = Fault Tolerance) ne doit pas être confondue avec la Haute Disponibilité. Il s'agit d'une version plus stricte de HA où la *disponibilité est de 100% et aucune donnée ne peut être perdue* (Wikipédia: "La tolérance aux pannes est la propriété qui permet à un système de continuer à fonctionner correctement en cas de défaillance d'un ou de certains de ses composants"). Seuls les systèmes critiques (santé, militaires, transport, industrie…) ont en général besoin d'un tel niveau de disponibilité.

Historiquement, cela signifiait une redondance matérielle complète. Dans un monde de micro-services, cela peut également être réalisé au niveau logiciel avec des clusters actifs-actifs. De plus, un véritable système de tolérance aux pannes devrait éviter une dégradation significative des performances vue par les utilisateurs finaux.

Par exemple, un lecteur RAID 1 offre une tolérance aux pannes transparente : en cas de panne, le processus écrit ou lit sans erreur après le basculement automatique sur le disque sain. Un cluster Kubernetes peut également atteindre la tolérance aux pannes en démarrant de nouveaux POD. Ou encore, un cache distribué en mémoire en cluster peut éviter de perdre une session HTTP.

Pour permettre la tolérance de panne d'un cluster, il faut obligatoirement *disposer d'un cluster actif/actif avec fort couplage* dans lequel les données de contexte sont répliquées à tout moment. Une autre solution (bien meilleure) est d’éviter tout simplement les données de contexte (en gardant les données de session dans le navigateur via un client JavaScript par exemple) ou de les stocker en base (SQL/NoSQL) ou en cache distribué (mais attention aux performances).

Pour disposer d'une tolérance de panne totalement transparente, il faut en plus prévoir un répartiteur de charge assurant les rejeux lui-même.

Attention à *bien qualifier les exigences* avant de construire une architecture FT car en général ces solutions :

* *Complexifient l'architecture* et la rendent donc moins robuste et plus coûteuse à construire, tester, exploiter.

* *Peuvent dégrader les performances* : les solutions de disponibilité et de performance vont en général dans le même sens (par exemple, un cluster de machines stateless va diviser la charge par le nombre de nœuds et dans le même temps, la disponibilité augmente), mais quelque fois, disponibilité et performance peuvent être antagonistes : dans le cas d'une architecture stateful, typiquement gérant les sessions HTTP avec un cache distribué (type Infinispan répliqué en mode synchrone ou un REDIS avec persistance sur le master), toute mise à jour transactionnelle de la session ajoute un surcoût lié à la mise à jour et la réplication des caches, ceci pour assurer le failover. En cas de plantage d'un des nœuds, l'utilisateur conserve sa session à la requête suivante et n'a pas à se reconnecter, mais à quel coût ?

* *Peuvent même dégrader la disponibilité* car tous les nœuds sont fortement couplés. Une mise à jour logicielle par exemple peut imposer l'arrêt de l'ensemble du cluster.

====

.Quelques solutions de disponibilité

|====
|Solution|Coût |Complexité de mise en œuvre indicative |Amélioration de la disponibilité indicative

|Disques en RAID 1 |XXX|X|XXX
|Disques en RAID 5 |X|X|XX
|Redondance des alimentations et autres composants |XX|X|XX
|Bonding des cartes Ethernet|XX|X|X
|Cluster actif/passif|XX|XX|XX
|Cluster actif/actif (donc avec LB)|XXX|XXX|XXX
|Serveurs/matériels de spare|XX|X|XX
|Bonne supervision système|X|X|XX
|Bonne supervision applicative|XX|XX|XX
|Systèmes de test de vie depuis un site distant|X|X|XX
|Astreintes dédiées à l’application, 24/7/365|XXX|XX|XXX
|Copie du backup du dernier dump de base métier sur baie SAN (pour restauration expresse) |XX|X|XX
|====


====
Exemple 1 : Pour atteindre la disponibilité de 98 % exigée, les dispositifs de disponibilité envisagés sont les suivants :

* Tous les serveurs en RAID 5 + alimentations redondées.

* Répartiteur HAProxy + keepalived actif/passif mutualisé avec les autres applications.

* Cluster actif /actif de deux serveurs Apache + mod_php.

* Serveur de spare pouvant servir à remonter la base MariaDB depuis le backup de la veille en moins de 2h.
====

====
Exemple 2 : Pour atteindre la disponibilité de 99.97% exigée, les dispositifs de disponibilité envisagés sont les suivants (pour rappel, l'application sera hébergée dans un DC de niveau tier 3) :

* Tous les serveurs en RAID 1 + alimentations redondées + interfaces en bonding.

* Répartiteur HAProxy + keepalived actif/passif dédié à l’application.

* Cluster actif /actif de 4 serveurs (soit une redondance 2N) Apache + mod_php.

* Instance Oracle en RAC sur deux machines (avec interconnexion FC dédiée).
====


=== Déploiement en production

[TIP]
====
Fournir ici le modèle de déploiement des composants en environnement cible sur les différents intergiciels et nœuds physiques (serveurs).
Ne représenter les équipements réseau (pare-feu, appliances, routeurs…) que s'ils aident à la compréhension.

Tout naturellement, on le documentera de préférence avec un diagramme de déploiement UML2 ou un diagramme de déploiement C4.

Pour les clusters, donner le facteur d'instanciation de chaque nœud.

Donner au besoin en commentaire les contraintes d'affinité (deux composants doivent s'exécuter sur le même nœud ou le même intergiciel) ou d'anti-affinité (deux composants ne doivent pas s'exécuter sur le même nœud ou dans le même intergiciel).

Identifier clairement le matériel dédié à l’application (et éventuellement à acheter).
====

====
Exemple :

image:{resourcesDir}/archi-infra.svg[Diagramme de déploiement MIEL]
====

=== Versions des composants d'infrastructure

[TIP]
====
Lister ici OS, bases de données, MOM, serveurs d'application, etc…
====
.Exemple de composants d'infrastructure
[cols="1e,2e,1e,2e"]
|====
|Composant|Rôle|Version |Environnement technique

|CFT
|Transfert de fichiers sécurisé
|X.Y.Z
|RHEL 6
|Wildfly
|Serveur d'application JEE
|9
|Debian 8, OpenJDK 1.8.0_144
|Tomcat
|Container Web pour les IHM
|7.0.3
|CentOS 7, Sun JDK 1.8.0_144
|Nginx
|Serveur Web
|1.11.4
|Debian 8
|PHP + php5-fpm
|Pages dynamiques de l'IHM XYZ
|5.6.29
|nginx
|PostgreSQL
|SGBDR
|9.3.15
|CentOS 7
|====

=== Matrice des flux techniques

[TIP]
====
Lister ici l'intégralité des flux techniques utilisés par l'application. Les ports d’écoute sont précisés. On détaille aussi les protocoles d'exploitation (JMX ou SNMP par exemple).

Dans certaines organisations, cette matrice sera trop détaillée pour un dossier d'architecture et sera maintenue dans un document géré par les intégrateurs ou les exploitants.

Il n'est pas nécessaire de faire référence aux flux applicatifs car les lecteurs ne recherchent pas les mêmes informations. Ici, les exploitants ou les intégrateurs recherchent l’exhaustivité des flux à fin d'installation et de configuration des pare-feu par exemple.

Les types de réseaux incluent les informations utiles sur le réseau utilisé afin d'apprécier les performances (TR, latence) et la sécurité: LAN, VLAN, Internet, LS, WAN…)
====

.Exemple partiel de matrice de flux techniques
[cols="1e,2e,2e,2e,1e,1e"]
|====
|ID|Source|Destination|Type de réseau|Protocole|Port d'écoute

|1|lb2|IP multicast 224.0.0.18|LAN|VRRP sur UDP|3222
|2|lb1|host1, host2|LAN|HTTP|80
|3|host3, host4, host5|bdd1|LAN|PG|5432
|4|sup1|host[1-6]|LAN|SNMP|199
|====

=== Environnements

[TIP]
====
Donner ici une vision générale des environnements utilisés par l'application. Les environnements les plus communs sont : développement, recette, pré-production/benchmarks, production, formation.

Dans les gros SI, il est souvent utile de segmenter les environnements en 'plateformes' (ou 'couloirs') constituées d'un ensemble de composants techniques isolés les uns des autres (même s'il peuvent partager des ressources communes comme des VM suivant la politique de l'organisation). Par exemple, un environnement de recette peut être constitué des plateformes `UAT1` et `UAT2` permettant à deux testeurs de travailler en isolation.

.Environnements
[cols='1,2,2,2']
|====
|Environnement| Rôle| Contenu | Plateforme

|Développement
|Déploiement continu (CD) pour les développeurs
|Branche `develop` déployée à chaque commit
|Un seul

|Recette
|Recette fonctionnelle par les testeurs
|Tag déployé à la fin de chaque Sprint
|UAT1 et UAT2
|====
====

=== Écoconception

[TIP]
====
Lister ici les mesures d'infrastructure permettant de répondre aux <<exigences_ecoconception,Exigences d'écoconception>>.

Les réponses à ces problématiques sont souvent les mêmes que celles aux exigences de performance (temps de réponse en particulier) et à celles des coûts (achat de matériel). Dans ce cas, y faire simplement référence.

Néanmoins, les analyses et solutions d'écoconception peuvent être spécifiques à ce thème. Quelques pistes d’amélioration de la performance énergétique :

* Mesurer la consommation électrique des systèmes avec les sondes http://www.powerapi.org/[PowerAPI] (développé par l'INRIA et l'université Lille 1).
* Utiliser des caches (cache d'opcode, caches mémoire, caches HTTP…).
* Pour des grands projets ou dans le cadre de l’utilisation d'un cloud CaaS, l’utilisation de cluster de containers (solution type Swarm, Mesos ou Kubernete) permet d'optimiser l'utilisation des VM ou machines physiques en les démarrant / arrêtant à la volée de façon élastique.
* Héberger ses serveurs dans un datacenter performant. Les fournisseurs de cloud proposent en général des datacenters plus performants que on-premises. L'unité de comparaison est ici le PUE (Power Usage Effectiveness), ratio entre l’énergie consommée par le datacenter et l’énergie effectivement utilisée par les serveurs (donc hors refroidissement et dispositifs externes). OVH propose par exemple des datacenter avec un PUE de 1.2 en 2017 contre 2.5 en moyenne.
* Néanmoins :
** vérifier l'origine de l'énergie (voir par exemple les analyses de Greenpeace en 2017 sur http://www.clickclean.org[l’utilisation d’énergie issue du charbon et du nucléaire] par Amazon pour son cloud AWS) ;
** garder en tête que l'énergie consommée par l'application coté client et réseau est très supérieure à celle utilisée coté serveur (par exemple, on peut estimer qu'un serveur consommant à peine plus qu'une station de travail suffit à plusieurs milliers voire dizaines de milliers d'utilisateurs). La réduction énergétique passe aussi par un allongement de la durée de vie des terminaux et l'utilisation de matériel plus sobre.
====
====
Exemple 1 : la mise en place d'un cache Varnish devant notre CMS reduira de 50% le nombre de construction de pages dynamiques PHP et permettra l'économie de deux serveurs.
====
====
Exemple 2 : L'application sera hébergée sur un cloud avec un PUE de 1.2 et une origine à 80 % renouvelable de l’énergie électrique.
====

=== Régulation de la charge

==== Coupe-circuits

[TIP]
====
Dans certains cas, des pics extrêmes et imprévisibles sont possibles (effet Slashdot).

Si ce risque est identifié, prévoir un système de fusible avec déport de toute ou partie de la charge sur un site Web statique avec message d'erreur par exemple.

Ce dispositif peut également servir en cas d’attaque de type DDOS et permet de gèrer le problème et non de le subir car on assure un bon fonctionnement acceptable aux utilisateurs déjà connectés.
====

==== Qualité de Service

[TIP]
====
Il est également utile de prévoir des systèmes de régulation applicatifs dynamiques, par exemple :

* Via du throttling (écrêtage du nombre de requêtes par origine et unité de temps). A mettre en amont de la chaîne de liaison.
* Des systèmes de jetons (qui permettent en outre de favoriser tel ou tel client en leur accordant un quota de jetons différents).
====
====
Exemple 1 : Le nombre total de jetons d'appels aux opérations REST sur la ressource `DetailArticle` sera de 1000. Au delà de 1000 appels simultanés, les appelants obtiendront une erreur d'indisponibilité 429 qu'ils devront gérer (et faire éventuellement des rejeux à espacer progressivement dans le temps).

.Exemple : répartition des jetons sera la suivante par défaut
|====
|Opération sur `DetailArticle`|Proportion des jetons

|GET|80%
|POST|5%
|PUT|15%
|====
====
====
Exemple 2 : un throttling de 100 requêtes par source et par minute sera mis en place au niveau du reverse proxy.
====

=== Gestion des timeouts

[TIP]
====
D'une façon générale, tous les appels distribués (en particulier HTTP(S) vers les API ou du stockage objet et appels vers les bases de données) doivent être limités en temps de connexion ET temps d'exécution. Sans ces timeouts, des contentions fatales pour les modules peuvent apparaître en cas de problèmes de performance.

Décrire ici les différents timeouts mis en œuvre sur les chaînes de liaison. Garder en tête que dans une chaîne de liaison allant du client à la persistance, les timeouts devraient diminuer au fur et à mesure qu'on avance dans la chaîne de liaison (exemple: 10 secs sur le Reverse proxy , 8 secs sur le endpoint REST, 5 secs sur la base de donnée).

En effet, dans le cas contraire, un composant technique peut continuer à traiter une requête alors que son composant appelant a déjà abandonné, ce qui pose à la fois des problèmes de gaspillage de ressource mais surtout des effets difficile à prévoir.

Éviter également d'utiliser la même valeur dans tous les composants techniques pour éviter les effets inattendus lié à la concomitance des timeouts.

====

====
Exemple :

|===
|Composant|Timeout (ms)

|Client Rest JavaScript | 5000
|API Gateway | 4000
|API Rest Node.js | 3500
|Base de donnée PG | 3000

|===

====

=== Exploitation

[TIP]
====
Lister ici les grands principes d’exploitation de la solution. Les détails (filesystems sauvegardés, plan de production, planification des traitements…) seront consigné dans un DEX (Dossier d’EXploitation) séparé.

Si cette application reste dans le standard de l’organisation, se référer simplement à un dossier commun.
====

==== Ordre d’arrêt/démarrage

[TIP]
====
Préciser ici l’ordre de démarrage des machines et composants entre eux ainsi que l’ordre d’arrêt. En fonction des situations, on peut faire figurer les composants externes ou non.

Le DEX contiendra une version plus précise de ce chapitre (notamment avec un numéro d'ordre SystemV ou un "Wants" SystemD précis), ce sont surtout les principes généraux des ordres d'arrêt et de démarrage qui doivent ici être décrits.

Le démarrage se fait en général dans le sens inverse des chaînes de liaison et l'arrêt dans le sens de la chaîne de liaison.

Préciser d'éventuelles problématiques en cas de démarrage partiel (par exemple, le pool de connexions du serveur d'application va-t-il retenter de se connecter à la base de donnée si elle n'est pas démarrée ? combien de fois ? quel est le degré de robustesse de la chaîne de liaison ? )
====
====
Exemple d'ordre de démarrage :

. pg1 sur serveur bdd1
. mq1 sur bdd1
. services1 sur serveurs host3, host4 et host5
. services2 sur serveurs host3, host4 et host5
. batchs sur serveurs host1, host2
. ihm sur serveurs host1, host2

Exemple d'ordre d'arrêt :

Inverse exact du démarrage
====

==== Opérations programmées

[TIP]
====
Lister de façon macroscopique (le DEX détaillera le plan de production précis) :

* Les batchs ou famille de batchs et leurs éventuelles inter-dépendances. Préciser si un ordonnanceur sera utilisé.
* Les traitements internes (tâches de nettoyage / bonne santé) du système qui ne remplissent uniquement des rôles techniques (purges, reconstruction d'index, suppression de données temporaires…)
====
====
Exemple 1 : le batch `traiter-demande` fonctionnera au fil de l'eau. Il sera lancé toutes les 5 mins depuis l’ordonnanceur JobScheduler.
====
====
Exemple 2 : le traitement interne `ti_index` est une classe Java appelant des commandes `REINDEX` en JDBC lancées depuis un scheduler Quartz une fois par mois.
====

==== Mise en maintenance

[TIP]
====
Expliquer (si besoin) les dispositifs et procédures permettant de mettre l'application 'offline' de façon explicite pour les utilisateurs.
====
====
Exemple : Nous utiliserons le F5 BigIp LTM pour afficher une page d'indisponibilité.
====

==== Sauvegardes et restaurations

===== Périmètre

[TIP]
====

Que sauvegarde-t-on ?

(Bien sélectionner les données à sauvegarder car le volume total du jeu de sauvegardes peut facilement atteindre dix fois le volume sauvegardé).

* des images/snapshots systèmes pour restauration de serveur ou de VM ?
* des systèmes de fichiers ou des répertoires ?
* des bases de données sous forme de dump ? sous forme binaire ?
* les logs ? les traces ?
====

Exemple:

* Sauvegarde système des VM
* Sauvegarde des bases PostgreSQL
* Sauvegardes des documents Ceph

===== Stratégie de sauvegarde

[TIP]
====
Donner la politique générale de sauvegarde. Elle doit répondre aux <<Exigences de RPO>>. De même les dispositifs de restauration doivent être compatibles avec les <<Exigences de disponibilité>>.

* Quels sont les backups à chaud ? à froid ?

* Quelle est la périodicité de chaque type de sauvegarde ? (ne pas trop détailler ici, ceci sera dans le DEX)

* Quelle est la stratégie de sauvegarde ?
** complètes ? incrémentales ? différentielles ? (prendre en compte les exigences en disponibilité. La restauration d'une sauvegarde incrémentale sera plus longue qu'une restauration de sauvegarde différentielle, elle-même plus longue qu'une restauration de sauvegarde complète) ;
** quel roulement ? (si les supports de sauvegarde sont écrasés périodiquement).

* Comment se fait le bilan de la sauvegarde ? par courriel ? où sont les logs ? Sont-ils facilement accessibles ? Contiennent-ils des informations sensibles ?

====

====
Exemple de roulement : jeu de 21 sauvegardes sur un an :

* 6 sauvegardes journalières incrémentales ;
* 1 sauvegarde complète le dimanche et qui sert de sauvegarde hebdomadaire ;
* 3 sauvegardes hebdomadaires correspondant aux 3 autres dimanches. Le support du dernier dimanche du mois devient le backup mensuel ;
* 11 sauvegardes mensuelles correspondant aux 11 derniers mois.
====

===== Outillage

[TIP]
====
Lister ici les outils utilisés pour les différents types de sauvegardes.

Quel outillage est mis en œuvre ?

* Simple cron + rsync + tar ?
* Outil Open Source orienté fichier comme « backup-manager » ?
* Outil orienté imaging de VM comme Veeam ou FSArchiver ?
* Outil orienté Cloud comme « Duplicity » ou « Restic » ?, etc.
* Outil de sauvegarde spécifique de base de données (comme MySqlDump, Barman...)

====

====
Exemple 1: Sauvegarde de la base PostgreSQL en streaming avec Barman avec un full chaque nuit.

Exemple 2: Sauvegarde journalière des documents via Duplicity avec stockage S3 sur OVH Public Cloud.

====

===== Traitements sur les sauvegardes

[TIP]
====
Lister ici les opérations réalisées sur les sauvegardes :

* Les sauvegardes sont-elles chiffrées ? si oui, chiffrement de la partition toute entière, fichier par fichier, les deux ? Faut-il chiffrer également le nom des répertoires et fichiers sauvegardés ? Préciser l'algorithme de chiffrement utilisé et comment seront gérées les clés (vaults, code de secours...).

* Les sauvegardes sont-elles compressées ? si oui, avec quel algorithme ? (lzw, deflate, lzma?, …), avec quel niveau de compression ? attention à trouver le compromis entre durée de compression / décompression et gain de stockage.

* Doit-on proposer des fonctionnalité de 'Point In Time Recovery' (PITR), pour permettre une restauration à la situation d'un instant précis paramétrable ?

* Les sauvegardes sont-elles protégées de l'écriture et de l'effacement (anti-ransomware) ? Si oui, de façon temporaire ou définitive ?

* Autres fonctionnalités ? (tests d'intégrité, nettoyage automatique dans l'archive, duplication de données, refactoring des fichiers dans l'archive, ...)

====
Exemple 1 : Déduplication des sauvegarde de niveau bloc via les CBT de l'hyperviseur.

Exemple 2 : Chiffrement des sauvegardes en AES256 via une partition chiffrée LUKS.

Exemple 3 : Compression lzma2 de niveau 6.

===== Modalités de stockage

[TIP]
====

Préciser le(s) media de stockage utilisé(s), son lieu de stockage...

* Le media est-il offline, online ou near-line (accessible via robot de sauvegarde dans une librairie de cassettes) ? (Attention, les sauvegardes online et même near-line sont sensibles aux erreurs humaines et aux ransonwares).

* Quelle technologie de stockage est utilisée pour les sauvegardes ? (bandes magnétiques type LTO ou DLT ? disques externes ? cartouches RDX ? cloud de stockage comme Amazon S3 ? support optique ? NAS ? …)

* Où sont stockées physiquement les sauvegardes ? (idéalement offline et le plus loin possible du système sauvegardé tout en permettant une restauration dans un temps compatible avec le RTO).

* Quelle est la législation du pays hébergeant nos sauvegardes ? Est-ce compatible avec les exigences juridiques comme le RGPD ? (voir le Cloud Act américain).

* Qui accède physiquement aux sauvegardes et à ses logs ? à la clé de chiffrement ? (penser aux exigences de confidentialité).

* Avons nous connaissance de toutes les dépendances externes pouvant nous ralentir (coffre de banque accessible en journée uniquement par exemple) ?

* Il est conseillé :

** d'utiliser un support distinct des données sources (ne pas sauvegarder sur un disque HD1 des données de ce même disque).
** de disposer d'au moins deux supports de stockage distincts si les données sont vitales à l'organisation.
** de faire en sorte que les sauvegardes ne soient pas modifiables par la machine qui a été sauvegardée (par exemple, une sauvegarde sur NAS peut être supprimée par erreur en même temps que les données sauvegardées)

* Règle des "3-2-1" pour les données importantes : il faut au moins deux copies en plus des données de production, stockées sur deux supports de technologie différentes et au moins une copie offline sur un site externe sécurisé (exemple: coffre-fort en banque).

====

====
Exemple 1: Pour la PME Boucherie Sanzot, on conservera une sauvegarde hebdomadaire des données de comptabilité en ligne sur le NAS + une copie offline sur disque externe chiffré et conservée dans le coffre d'une voiture. On conservera sur les deux supports 12 sauvegardes mensuelles et une sauvegarde annuelle, ce qui permet de revenir jusqu'à 2 ans dans le passé.

Exemple 2: Pour la sauvegarde des données d'imposition, chaque transaction vers la base de donnée sera sauvegardée en barman en utilisant les journaux WAL. Chaque nuit, une sauvegarde full barman de la base sera effectuée. On conservera 7J + 4 semaines + 12 mois + 1 an sur sauvegarde online (disques durs) et en near-ligne sur librairie de sauvegarde à base de bandes LTO. Les données seront chiffrées et compressées. Les sauvegardes hebdomadaires seront dupliquées et stockées sur bande offline sur un site distant dédié.

====

===== Restauration

[TIP]
====
Toujours garder à l'esprit que ce que nous voulons _vraiment_, ce sont des restaurations, pas des sauvegardes. Il est crucial de s'assurer que la restauration sera fonctionnelle :

* Les sauvegardes sont-elles correctes et complètes ?
* Quels tests de restauration sont prévus ? à quelle fréquence (une fois par an est un minium) ?
* Combien de temps va prendre une restauration (benchmarks) ? Est-ce compatible avec le RTO ?

* Avons nous suffisamment de ressources hardware pour la restauration dans le temps imparti par le RTO (stockage intermédiaires, CPU et mémoire pour la décompression/déchiffrement , etc…) ?

* Comment se fait le bilan de la restauration ? où sont les logs ? Sont-ils facilement accessibles ? Contiennent-ils des informations sensibles ?

====

====
Exemple: Un test de restauration des données de production sera effectuée en pré-production au minimum une fois par an.
====



==== Archivage

[TIP]
====
Décrire ici les dispositifs permettant de répondre aux <<exigences-archivage>> avec les modalités de stockage suivantes :

* La technologie : idéalement, on dupliquera par sécurité l'archive sur plusieurs supports de technologies différentes (bande + disque dur par exemple).
* Un lieu de stockage spécifique et distinct des sauvegardes classiques (coffre-fort en banque par exemple).
====
====
Exemple : les relevés bancaires de plus de 10 ans seront archivés sur bande LTO et disque dur. Les deux supports seront stockés en coffre dans deux banques différentes.
====

==== Purges

[TIP]
====
Donner ici les dispositifs techniques répondant aux <<exigences-purge>>.
====
====
Exemple : l'historique des consultations sera archivé par un dump avec une requête SQL de la forme `COPY (SELECT * FROM matable WHERE …) TO '/tmp/dump.tsv'` puis purgé par une requete SQL `DELETE` après validation par l'exploitant de la complétude du dump.
====

==== Logs

[TIP]
====
Sans être exhaustif sur les fichiers de logs (à prévoir dans le DEX), présenter la politique générale de production et de gestion des logs :

* Quelles sont les politiques de roulement des logs ? le roulement est-il applicatif (via un `DailyRollingFileAppender` log4j par exemple) ou système (typiquement par le démon logrotate) ?
* Une centralisation de logs est-elle prévue ? (indispensable pour les architectures SOA ou micro-services). Voir par exemple la stack ELK.
* Quel est le niveau de prolixité prévu par type de composant ? le débat en production est en général entre les niveaux WARN et INFO. Si les développeurs ont bien utilisé le niveau INFO pour des informations pertinentes (environnement au démarrage par exemple) et pas du DEBUG, fixer le niveau INFO.
* Des mesures anti-injection de logs sont-elles prévues (échappement XSS) ?

====
====
Exemple 1 : les logs applicatifs du composant service-miel seront en production de niveau INFO avec roulement journalier et conservation deux mois.
====
====
Exemple 2 : les logs seront échappés à leur création via la méthode `StringEscapeUtils.escapeHtml()` de Jakarta commons-lang.
====

==== Supervision

[TIP]
====
La supervision est un pilier central de la disponibilité en faisant diminuer drastiquement le MTTD (temps moyen de détection de la panne).

Idéalement, elle ne sera pas uniquement réactive mais également proactive (detection des signaux faibles).

Les métriques sont des mesures brutes (% CPU, taille FS, taille d'un pool…) issues de sondes système, middleware ou applicatives.

Les indicateurs sont des combinaisons logiques de plusieurs métriques disposant de seuils (ex : 'niveau critique si l'utilisation de CPU sur le serveur s1 reste au delà de 95% pendant plus de 5 minutes').
====

===== Supervision technique

[TIP]
====
Lister les métriques :

* Système (% d'utilisation de file system, load, volume de swap in/out, nombre de threads total …)
* Middleware (% de HEAP utilisée sur une JVM, nb de threads sur la JVM, % utilisation d'un pool de threads ou de connexions JDBC ..)
====
====
Exemple : on mesura le % de wait io et la charge serveur.
====

===== Supervision applicative

[TIP]
====
Lister les métriques applicatives (développés en interne). lls peuvent être techniques ou fonctionnels :

* Nombre de requêtes d'accès à un écran.
* Nombre de contrats traités dans l'heure.
* …

Il est également possible de mettre en place des outils de BAM (Business Activity Monitoring) basées sur ces métriques pour suivre des indicateurs orientés processus.
====
====
Exemple : l'API REST de supervision applicative proposera une ressource Metrique contenant les métriques métier principaux : nombre de colis à envoyer, nombre de préparateurs actifs…
====

===== Outil de pilotage de la supervision

[TIP]
====
Un tel outil (comme Nagios, Hyperic HQ dans le monde Open Source) :

* Collecte les métriques (en SNMP, JMX, HTTP …) de façon périodique.
* Persiste les métriques dans un type de base de données de séries chronologiques (comme RRD).
* Consolide les indicateurs depuis les métriques.
* Affiche les tendances dans le temps de ces indicateurs.
* Permet de fixer des seuils d’alerte basés sur les indicateurs et de notifier les exploitants en cas de dépassement.
====
====
Exemple : la pilotage de la supervision se basera sur la plate-forme Grafana.
====

===== Alerting

[TIP]
====
Préciser ici les conditions d'alertes et le canal utilisé
====
====
Exemple : SMS si aucune demande depuis les 4 dernières heures ou si le nombre d'erreurs techniques d'un composant dépasse 10/h.
====

===== Suivi des opérations programmées

[TIP]
====
Indiquer l’ordonnanceur ou le planificateur utilisé pour piloter les jobs et consolider le plan de production (exemple : VTOM, JobScheduler, Dollar Universe, Control-M…). Détailler les éventuelles spécificités de l’application :

* Degré de parallélisme des jobs
* Plages de temps obligatoires
* Rejeux en cas d'erreur
* …

Les jobs doivent-ils produire un rapport d'exécution ? sous quelle forme et avec quel contenu ?
====
====
Exemple 1 : les jobs seront ordonnancés par l'instance JobScheduler de l'organisation.

* Les jobs ne devront jamais tourner les jours féries.
* Leur exécution sera bornée aux périodes 23h00 - 06h00. Leur planification devra donc figurer dans cette plage ou ils ne seront pas lancés.
* On ne lancera pas plus de cinq instances du job J1 en parallèle.

Exemple 2 : Les jobs devront produire un rapport d'exécution à chaque lancement (avec des données de base comme le nombre d'éléments traités, la durée du traitement et tout indicateur pertinent).
====

===== Supervision boite noire

[TIP]
====
Il est également fortement souhaitable et peu coûteux de prévoir un système de tests de supervision boite-noire (via des scénarios déroulés automatiquement). L'idée est ici de tester un système dans son ensemble et avec une vue end-user la plus externe possible (à l'inverse d'une supervision whitebox pour laquelle on supervise des composants bien précis avec un comportement attendu).

En général, ces tests sont simples (requêtes HTTP depuis un curl croné par exemple). Ils doivent être lancés depuis un ou plusieurs sites distants pour détecter les coupures réseaux.

Il est rarement nécessaire qu'ils effectuent des actions de mise à jour. Si tel est le cas, il faudra être en mesure d'identifier dans tous les composants les données issues de ce type de requêtes pour ne pas polluer les données métier et les systèmes décisionnels.
====
====
Exemple pour un site Internet : des tests de supervision boite noire seront mis en œuvre via des requêtes HTTP lancées via l'outil uptrends.com. En cas de panne, un mail est envoyé aux exploitants.
====

===== Métrologie

[TIP]
====
Suit-on les performances de l'application en production ? Cela permet :

* De disposer d'un retour factuel sur les performances _in vivo_ et d'améliorer la qualité des décisions d’éventuelles redimensionnement de la plate-forme matérielle.
* De détecter les pannes de façon proactive (suite à une chute brutale du nombre de requêtes par exemple).
* De faire de l'analyse statistique sur l’utilisation des composants ou des services afin de favoriser la prise de décision (pour le décommissionnement d'une application par exemple).

Il existe trois grandes familles de solutions :

* Les APM (Application Performance Monitoring) : outils qui injectent des sondes sans impact applicatifs, qui les collectent et les restituent (certains reconstituent même les chaînes de liaison complètes via des identifiants de corrélations injectés lors des appels distribués). Exemple : Oracle Enterprise Manager, Oracle Mission Control, Radware, BMC APM, Dynatrace , Pinpoint en OpenSource …). Vérifier que l'overhead de ces solutions est négligeable ou limité et qu'on ne met en péril la stabilité de l'application.
* La métrologie «maison» par logs si le besoin est modeste.
* Les sites de requêtage externes qui appellent périodiquement l'application et produisent des dashboards. Ils ont l'avantage de prendre en compte les temps WAN non disponibles via les outils internes. A utiliser couplés à la supervision boite noire (voir plus haut).
====
====
Exemple : les performances du site seront supervisées en continu par `pingdom.com`. Des analyses de performances plus poussées seront mises en œuvre par Pinpoint en fonction des besoins.
====

=== Migrations

[TIP]
====
Ce chapitre décrit les éventuelles migration requises depuis des systèmes plus anciens.

Décrire de façon macroscopique la procédure envisagée ainsi que les retours arrières prévus.

Décrire éventuellement un fonctionnement 'à blanc' en parallèle de l'ancien système avant activation.
====
====
Exemple 1 : Le composant X sera remplacé par les services Y. Ensuite les données Oracle Z du silo seront migrées en one-shot via un script PL/SQL + DBLink vers l’instance XX avec le nouveau format de base du composant T.
====
====
Exemple 2 : en cas de problème sur le nouveau composant, un retour arrière sera prévu : les anciennes données seront restaurées dans les deux heures et les nouvelles données depuis la bascule seront reprise par le script S1.
====

=== Décommissionnement

[TIP]
====
Ce chapitre sera instruit quand l’application arrive en fin de vie et devra être supprimée ou remplacée. Elle décrit entre autres :

* Les données à archiver ou au contraire à détruire avec un haut niveau de confiance.
* Les composants physiques à évacuer ou à détruire.
* Les procédures de désinstallation coté serveur et/ou client (il est courant de voir des composants obsolètes toujours s’exécuter sur des serveurs et occasionner des problèmes de performance et de sécurité passant sous le radar).
* Les contraintes de sécurité associées au décommissionnement (c’est une étape sensible souvent négligée, on peut retrouver par exemple des disques durs remplis de données très sensibles suite à un don de matériel).
====

====
Exemple : Les serveurs X, Y et Z seront transmis au service d’action sociale pour don caritatif après avoir effacé intégralement les disques durs via la commande shred, 3 passes.
====

:leveloffset!:
[#volet-dimensionnement]
:leveloffset: +1


= Volet dimensionnement

Les autres volets du dossier sont accessibles xref:liste-volets[d'ici].

Cette section décrit le dimensionnement du projet.
Le but est de déterminer la taille de l'infrastructure nécessaire au projet.

toc::[]

== Documentation de Référence

.Références documentaires dimensionnement
[cols="1e,1e,4e,4e"]
|====
|N°|Version|Titre/URL du document|Détail

|1|1.2|Rapport_benchmark_xyz.pdf|
|2|2019|Rapport INSEE sur les entreprises françaises|


|====


== Non statué

=== Points soumis à étude complémentaire

.Points soumis à étude complémentaire
[cols="1e,1e,1e,2e,2e"]
|====
|ID| Détail |Statut |Porteur du sujet  | Échéance

|1| Capacité disques SSD |EN_COURS | XYZ | 01/01/2022

|====


=== Hypothèses

[TIP]
====
Donner ici les hypothèses structurantes prises pour le dimensionnement
====

====
Exemple:

.Hypothèses
[cols="1e,4e"]
|====
|ID|Détail

|1|Nous estimons que 10M de personnes téléchargeront l'application StopCovid

|====

====

== Contraintes

[TIP]
====
Les contraintes sont les limites applicables aux exigences sur le projet.

Il est intéressant de les expliciter pour obtenir des exigences réalistes. Par exemple, il ne serait pas réaliste d'exiger des temps de réponse d'un web service incompatibles avec le débit du réseau sous-jacent.

====


=== Contraintes stockage

TIP: Lister ici les éventuelles contraintes liées aux disques

[Exemple]
====
Exemple : L'espace disque maximal allouable à une VM est de 2 To.
====

=== Contraintes CPU

TIP: Lister ici les éventuelles contraintes liées à la puissance de calcul
[Exemple]
====
Exemple 1 : Une VM sera dotée au maximum de 10 VCPU
====

====
Exemple 2 : L'ensemble des pods de l'application ne devra pas demander plus de 1 CPU par node.
====

=== Contraintes mémoire

TIP: Lister ici les éventuelles contraintes liées à la mémoire
[Exemple]
====
Exemple : un pod ou un job Kubernetes ne devra pas utiliser plus de 6 Go de RAM
====

=== Contraintes réseau

TIP: Lister ici les éventuelles contraintes de volume réseau utilisé
[Exemple]
====
Exemple 1 : La latence minimale des requêtes sur le WAN entre Londres et Tokyo est de 250 ms
====

[Exemple]
====
Exemple 2 : Le réseau Ethernet du Datacenter dispose d'une bande passante de 40 Gbps.
====

== Exigences

[TIP]
====
Il est crucial de récupérer un maximum d'informations issues de la production plutôt que des estimations car ces dernières se révèlent souvent loin de la réalité. C'est d'autant plus difficile s'il s'agit d'un nouveau projet. Prévoir alors une marge importante. Les informations données ici pourront serviront d'entrants au SLO (Objectif de Service fixé par les exploitants).
====

[TIP]
====
Les sections suivantes portant sur les calculs de volumétrie statiques et dynamiques donnent des exemples de calculs et d'élements à prendre en compte. Sur le plan de la forme, il peut être préférable de remplacer le texte par des feuilles de calculs dans un tableur. Pour un projet complexe ou aux hypothèses mouvantes, c'est indispensable.

====

=== Volumétrie statique

TIP: Il s'agit des métriques permettant de déterminer le volume de stockage *cumulé* du projet. Penser à bien préciser les hypothèses prises pour les métriques estimées. Il sera ainsi possible de les revoir si de nouveaux éléments métier apparaissent.

==== Métriques

TIP: Il s'agit des données métier mesurées ou estimées qui serviront d'entrants au calcul des besoins techniques de stockage.

[cols="e,e,e,e,e,e,e"]
|====
|Métrique|Description |Mesurée ou Estimée ? | Valeur | Augmentation annuelle prévisionnelle (%) |  Source| Détail/hypothèses

|S1 |Nombre d'entreprises éligibles | Estimé |  4M | +1% |  INSEE [2]  | On considère que MIEL ne concerne pas les auto-entrepreneurs
|S2 |Taille moyenne d'un PDF | Mesurée | 40Ko  | 0%| Exploitants |
|====

==== Estimation besoins de stockage

[TIP]
====
Lister ici les besoins en stockage de chaque composant une fois l’application arrivée à pleine charge (volumétrie à deux ans par exemple).

Prendre en compte :

* La taille des bases de données.
* La taille des fichiers produits.
* La taille des files.
* La taille des logs.
* L'espace nécessaire dans un éventuel stockage objet (S3, Swift, Ceph…)
*  …

Ne pas prendre en compte :

* Le volume lié à la sauvegarde : elle est gérée par les exploitants.
* Le volume des binaires (OS, intergiciels…) qui est à considérer par les exploitants comme une volumétrie de base d'un serveur (le ticket d'entrée) et qui est de leur ressort.
* Les données archivées qui ne sont donc plus en ligne.

Fournir également une estimation de l'augmentation annuelle en % du volume pour permettre aux exploitants de commander ou réserver suffisamment de disque.

Pour les calculs de volumétrie, penser à prendre en compte les spécificités de l'encodage (nombre d’octets par caractère, par date, par valeur numérique…).

Pour une base de donnée, prévoir l'espace occupé par les index et qui est très spécifique à chaque application. Une (très piètre) estimation préliminaire est de doubler l'espace disque (à affiner ensuite).

N'estimer que les données dont la taille est non négligeable (plusieurs Gio minimum).
====

====
. Exemple de volumétrie statique du composant C :
|====
|Donnée|Description|Taille unitaire|Nombre d'éléments à 2 ans|Taille totale|Augmentation annuelle

|Table Article
|Les articles du catalogue
|2Kio
|100K
|200 Mio
|5 %

|Table Commande
|Les commandes clients
|10Ko
|3M
|26.6 Gio
|10 %

|Logs
|Les logs applicatifs (niveau INFO)
|200 o
|300M
|56 Gio
|0 % (archivage)
|====
====

=== Volumétrie dynamique

TIP: Il s'agit des métriques par durée (année, mois, heure…) et permettant de déterminer la charge appliquée sur l'architecture, ce qui aidera à dimensionner les systèmes en terme de CPU, bande passante et performances des disques.

==== Métriques

TIP: Ce sont les données métier mesurées ou estimées qui serviront d'entrants au calcul de la charge.

[cols="e,e,e,e,e,e,e,e"]
|====
|Métrique|Description |Mesurée ou Estimée ? | Valeur | Augmentation annuelle prévisionnelle (%) | Saisonnalité|  Source| Détail/hypothèses

|D1 |Proportion d'utilisateurs se connectant au service / J | Estimée | 1%  | +5%
a|

- Constant sur l'année
- Constant sur la semaine
- 3 pics à 20% de la journée à 8:00-9:00, 11:00-12:00 et 14:00-15:00
| | Les utilisateurs sont des professionnels utilisant l'application depuis la France métropolitaine aux heures de bureau standards
|====


==== Estimation de la charge

[TIP]
====
Il s'agit ici d'estimer le nombre d'appels aux composants et donc le débit cible (en TPS = Transactions par seconde) que devra absorber chacun d'entre eux. Un système bien dimensionné devra présenter des temps de réponse moyen du même ordre en charge nominale et en pic.

Toujours estimer le "pic du pic", c'est à dire le moment où la charge sera maximale suite au cumul de tous les facteurs (par exemple pour un système de comptabilité : entre 14 et 15h  un jour de semaine de fin décembre).

Ne pas considérer que la charge est constante mais prendre en compte :

* Les variations journalières. Pour une application de gestion avec des utilisateurs travaillant sur des heures de bureau, on observe en général des pics du double de la charge moyenne à 8h-9h, 11h-12h et 14h-15h. Pour une application Internet grand public, ce sera plutôt en fin de soirée. Encore une fois, se baser sur des mesures d'applications similaires quand c'est possible plutôt que sur des estimations.
* Les éléments de saisonnalité. La plupart des métiers en possèdent : Noël pour l'industrie du chocolat, le samedi soir pour les admissions aux urgences, juin pour les centrales de réservation de séjours etc. La charge peut alors doubler voire plus. Il ne faut donc pas négliger cette estimation.

Si le calcul du pic pour un composant en bout de chaîne de liaison est complexe (par exemple, un service central du SI exposant des données référentiel et  appelé par de nombreux composants qui ont chacun leur pic), on tronçonnera la journée en intervalles de temps suffisamment fins (une heure par exemple) et on calculera sur chaque intervalle la somme mesurée ou estimée des appels de chaque appelant (batch ou transactionnel) pour ainsi déterminer la sollicitation cumulée la plus élevée.

Si l'application tourne sur un cloud de type PaaS, la charge sera absorbée dynamiquement mais veiller à estimer le surcoût et à fixer des limites de consommation cohérentes pour respecter le budget tout en assurant un bon niveau de service.
====

.Exemple : estimation volumétrie dynamique de l'opération REST `GET Detail` de l'application MIEL
|====
|Taux maximal d’utilisateurs connectés en même temps en pic annuel | S1 x F1 x 0.2 = 8K /H
|Durée moyenne d'une session utilisateur
|15 mins
|Nombre d'appel moyen du service par session
|10
|Charge (Transaction / seconde)
|8K / 4 x 10 / 3600 =  5.5 Tps
|====


[TIP]
====
Pour un composant technique (comme une instance de base de donnée) en bout de chaîne et sollicité par de nombreux services, il convient d'estimer le nombre de requêtes en pic en cumulant les appels de tous les clients et de préciser le ratio lecture /écriture quand cette information est pertinente (elle est très importante pour une base de donnée).

Le niveau de détail de l'estimation dépend de l'avancement de la conception de l’application et de la fiabilité des hypothèses.

Dans l'exemple plus bas, nous avons déjà une idée du nombre de requêtes pour chaque opération. Dans d’autres cas, on devra se contenter d'une estimation très large sur le nombre de requêtes total à la base de données et un ratio lecture /écriture basée sur des abaques d'applications similaires. Inutile de détailler plus à ce stade.

Enfin, garder en tête qu'il s'agit simplement d'estimation à valider lors de campagnes de performances puis en production. Prévoir un ajustement du dimensionnement peu après la MEP.
====

====
Exemple : la base de donnée Oracle BD01 est utilisée en lecture par les appels REST `GET DetailArticle` fait depuis l'application end-user et en mise à jour par les appels POST et PUT sur `DetailArticle` issus du batch d'alimentation B03 la nuit entre 01:00 et 02:00.

.Exemple estimations nombre de requêtes SQL en pic vers l'instance BD01 de 01:00 à 02:00 en décembre
|====
|Taux maximal d’utilisateurs connectés en même temps |0.5%
|Nombre maximal d’utilisateurs connectés concurrents
|5K
|Durée moyenne d'une session utilisateur
|15 mins
|Nombre d'appel moyen du service `GET DetailArticle` par session
|10
|Charge usagers GET DetailArticle (Transaction / seconde)
|(10/15) x 5K / 60 =  55 Tps
|Nombre de requête en lecture et écriture par appel de service
|2 et 0
|Nombre d'appel journalier du service `POST DetailArticle` depuis le batch B03
|4K
|Nombre de requêtes INSERT et SELECT par appel de service
|3 et 2
|Nombre journalier d'articles modifiés par le batch B03
|10K
|Nombre de requêtes SELECT et UPDATE
|1  et 3
|Nombre de SELECT / sec
|55x2 + 2 x 4K/3600 + 1 x 10K/3600=   115 Tps
|Nombre de INSERT / sec
|0 + 3 x 4K/3600 = 3.4 Tps
|Nombre de UPDATE / sec
|0 + 3 x 10K/3600 = 8.3 Tps
|====
====

=== Exigences de temps de réponse

==== Temps de Réponse des IHM

[TIP]
====
Si les clients accèdent au système en WAN (Internet, VPN, LS …), préciser que les exigences de TR sont données hors transit réseau car il est impossible de s’engager sur la latence et le débit de ce type de client.

Dans le cas d’accès LAN, il est préférable d’intégrer le temps réseau, d’autant que les outils de test de charge vont déjà le prendre en compte.

Les objectifs de TR sont toujours donnés avec une tolérance statistique (90éme centile par exemple) car la réalité montre que le TR est très fluctuant car affecté par un grand nombre de facteurs.

Inutile de multiplier les types de sollicitations (en fonction de la complexité de l’écran par exemple) car ce type de critère n’a plus grand sens aujourd'hui, particulièrement pour une application SPA).
====
====
.Exemple de types de sollicitation :
[cols='3e,1e,1e,1e']
|====
|Type de sollicitation|Bon niveau|Niveau moyen|Niveau insuffisant

|Chargement d’une page
|< 0,5 s
|< 1 s
|> 2 s

|Opération métier
|< 2 s
|< 4 s
|> 6 s

|Édition, Export, Génération
|< 3 s
|< 6 s
|> 15 s
|====

Exemple d'acceptabilité des TR :

Le niveau de respect des exigences de temps de réponse est bon si :

* Au moins 90 % des temps de réponse sont bons.
* Au plus 2% des temps de réponse sont insuffisants.

Acceptable si :

* Au moins 80 % des temps de réponse sont bons.
* Au plus 5 % des temps de réponse sont insuffisants.

En dehors de ces valeurs, l’application devra être optimisée et repasser en recette puis être soumise à nouveau aux tests de charge.
====

==== Durée d’exécution des batchs

[TIP]
====
Préciser ici dans quel intervalle de temps les traitements par lot doivent s’exécuter.
====
====
Exemple 1 : La fin de l’exécution des batchs étant un pré-requis à l’ouverture aux usagers, ces premiers doivent impérativement se terminer avant la fin de la plage batch définie plus haut.
====

====
Exemple 2 : le batch mensuel B1 de consolidation des comptes doit s’exécuter en moins de 4 J.
====

====
Exemple 3 : les batchs et les IHM pouvant fonctionner en concurrence, il n’y a pas de contrainte stricte sur la durée d’exécution des batchs mais pour assurer une optimisation de l’infrastructure matérielle, on favorisera la nuit pendant laquelle les sollicitations IHM sont moins nombreuses.
====


== Dimensionnement cible

[TIP]
====
Nous donnons un dimensionnement final devant supporter la volumétrie statique et dynamique et respecter les exigences.
====

=== Estimation des besoins en ressources par composant technique

[TIP]
====
Donner ici RAM, disque et CPU par instance de composant technique déployé (à affiner après campagne de performance ou MEP).

====
====
Exemple :

.Estimation des besoins en ressources par composant technique
[cols="2e,1e,1e,3e,2e"]
|====
| Unité déployable | Besoin en (V)CPU par instance| Besoin mémoire par instance (Mio) |  Périodes d'activité | Commentaires

| `tomcat-batchs1`
| <négligeable>
| 1024
| Toutes les heures, 24/7/365
| Le serveur d'application reste démarré même en dehors de l'exécution des jobs

| `spa`
| <négligeable>
| 50
| 24/6, activité principale 8-17h Europe/Paris lun-ven
|Appli Web SPA, s'exécute dans le navigateur

| `bdd-postgresql`
| 2
| 2024
| 24/7, activité principale 8-17h Europe/Paris lun-ven
| Instance Postgresql
|====
====

=== Dimensionnement des machines

Voir le xref:{voletInfrastructureLink}#_déploiement_en_production[modèle de déploiement].

[TIP]
====

Cette section fournit le dimensionnement final des machines nécessaires

* Pour les VM, attention à vérifier qu'un VCPU = 1 cœur physique (et non un thread si hyperthreading activé)
* Le disque interne concerne le disque nécessaire à l'OS et aux binaires. Pour une machine physique, il s'agit de stockage local (disques locaux SDD, NMVe ou HDD). Pour une VM, il peut s'agir d'un disque local sur la machine physique exécutant la VM ou d'un SAN.
* Le disque distant concerne du stockage sur une baie de disque (SAN)
* Le stockage externe hors SAN concerne du stockage fichier sur un filesystème distribué (NFS, CIFS, WebDav, …) ou un stockage objet (Swift, S3, …)
====

.Dimensionnement des machines
[cols='1e,3e,1e,1e,1e,1e,1e']
|====
|Zone | Type de machine | Nb de machines | Nb (V)CPU  | Mémoire (Gio) | Disque interne (Gio) | Disque distant SAN (Gio)

|Zone 01
|VM serveur applicatif
|3
|2
|4
|100
|0

|Zone 02
|Machine physique Base de données
|1
|2
|6
|50
|1024

|====

.Dimensionnement du stockage externe hors SAN
[cols='1e,3e,3e']
|====
|Nature|Taille (Gio)|Type(s) de machine utilisant ce partage

|NFS (montage NAS)
|248
|Machine physique Base de données

|OpenStack Object Storage ("Swift")
|20
|VM serveur applicatif

|====

:leveloffset!:
[#volet-securite]
:leveloffset: +1


= Volet sécurité

Les autres volets du dossier sont accessibles xref:{listeVoletsLink}[d'ici].

Cette section décrit l'ensemble des dispositifs mis en œuvre pour empêcher l'utilisation non-autorisée, le mauvais usage, la modification illégitime ou le détournement des modules applicatifs.

toc::[]

== Documentation de Référence

[TIP]
====
Mentionner ici les documents d'architecture de référence (mutualisés). Ce document ne doit en aucun cas reprendre leur contenu sous peine de devenir rapidement obsolète et non maintenable.
====

.Références documentaires sécurité
[cols="1e,1e,3e,3e"]
|====
|N°|Version|Titre/URL du document|Détail

|1|1.0|Dispositifs_securite.pdf|Catalogue de dispositifs de sécurité habilités
|2|latest|Normes sécurité société|http://masociete/monurl
|====

== Non statué

=== Points soumis à étude complémentaire

.Points soumis à étude complémentaire
[cols="1e,3e,1e,1e,2e"]
|====
|ID|Détail|Statut|Porteur du sujet | Échéance

|ES1
|Il conviendra de valider que les dispositifs anti-CSRF mis en place résolvent également les failles liées au couplage TLS + compression (type CRIME ou BREACH).
|EN_COURS
|Équipe sécurité
|AVANT 2040

|====

=== Hypothèses

.Hypothèses
[cols="e,e"]
|====
|ID|Détail

|HS1
|La solution SAML actuellement en place dans l’organisation ne permet pas de répondre aux besoins d’authentification exprimés pour cette application Internet. Une solution OpenID Connect sera proposée.
|====

== Contraintes

[TIP]
====
Lister ici les contraintes relatives à la sécurité, ceci inclut par exemple mais pas seulement :

* L'isolation des composants au sein de zones réseaux étanches (DMZ, pare-feux, reverse-proxy…)
* Les normes applicables (comme les politiques de mot de passe)
* Les contraintes légales (RGPD par exemple)

====
====
Exemple 1 : la politique de mot de passe devra se conformer à la norme xyz
====
====
Exemple 2 : il est formellement interdit à un composant de la zone internet d'accéder à la zone intranet
====
====
Exemple 3 : en application du RGPD, les données utilisateur devront être chiffrées
====

== Exigences

[TIP]
====
Présenter ici les exigences, *pas les dispositifs y répondant*. Ceux-ci seront détaillés au chapitre 3.

Pour les projets particulièrement sensibles, prévoir un dossier d’analyse de risque. Pour cela, utiliser par exemple la méthode https://www.ssi.gouv.fr/guide/la-methode-ebios-risk-manager-le-guide/[EBIOS Risk Manager] (Expression des Besoins et Identification des Objectifs de Sécurité).
====

[[exigences-integrite]]
=== Exigences d'intégrité

[TIP]
====
L’intégrité concerne la durabilité, la justesse et le niveau de confiance dans les données de l’application.

Gérer l’intégrité des données consiste à vérifier qu’elle ne peuvent être altérées ou supprimées (involontairement, suite à un crash disque par exemple) ou volontairement, par exemple dans le cadre d’une attaque de type "man in the middle" ou par une personne s’étant octroyé des droits indus.

Attention à ne pas multiplier les classes de données.Il est possible de ne définir qu’une seule classe de donnée pour l’ensemble de l’application (cas courant).
====

.Niveau d'intégrité exigée par classe de données (exemple)
[cols='2e,1e,1e,1e,1e']
|====
|Classe de données
|Niveau « Non intègre » [small]#(La donnée peut ne pas être totalement intègre)#
|Niveau « Détectable » [small]#(La donnée peut ne pas être intègre si l'altération est identifiée dans un délai raisonnable)#
|Niveau « Maîtrisé » [small]#(La donnée peut ne pas être intègre, si l'altération est identifiée et l'intégrité du bien essentiel retrouvée)#
|Niveau « Intègre » [small]#(La donnée doit toujours être rigoureusement intègre)#

|Données de la base métier
|
|
|
|X

|Données archivées
|
|X
|
|

|Données calculées stats entreprises
|
|
|X
|

|Silo NoSQL des données Big Data avant consolidation
|X
|
|
|

|Sources de l’application
|
|
|
|X

|Avis d‘imposition en PDF
|
|
|
|X
|====

[[exigences-confidentialite]]
=== Exigences de confidentialité

[TIP]
====
[quote ]
La confidentialité est le fait de s’assurer que l’information n’est accessible qu’à ceux dont l’accès est autorisé (norme ISO 27018).

Attention à ne pas multiplier les classes de données.Il est possible de ne définir qu’une unique classe de donnée pour l’ensemble de l’application (cas courant).
====

.Niveau de confidentialité exigée par classe de données
[cols="e,e,e,e,e"]
|====
|Classe de données | Niveau « Public » [small]#(Tout le monde peut accéder à la donnée)#
|Niveau Limité » [small]#(La donnée n’est accessible qu’aux personnes habilitées)#
|Niveau « Réservé » [small]#(La donnée n’est accessible qu’au personnel interne habilité)#
|Niveau « Privé » [small]#(La donnée n’est visible que par l’intéressé(e))#

|Contenu éditorial
|X
|
|
|

|Données de profil de l'utilisateur
|
|X
|
|

|Historique du compte
|
|
|X
|

|Logs techniques des activités
|
|
|X
|

|Données RH de type "aides sociales aux employés"
|
|
|
|X
|====

[[exigences-identification]]
=== Exigences d'identification

[TIP]
====
L’identification est l’ensemble des dispositifs permettant de différentier un utilisateur d’un autre (mais sans vérifier qu’il est bien celui qu’il prétend être).
====

====
Exemple 1 : Un utilisateur ne peut avoir qu’un unique identifiant et un identifiant ne peut être partagé par plusieurs utilisateurs.L'adresse e-mail personnelle est donc un bon identifiant.
====
====
Exemple 2 : L’identité d’un internaute fera l’objet d’un test d’existence avant tout appel de service.
====
====
Exemple 3 : Un ID est non supprimable, non modifiable et non réutilisable.
====

[[exigences-authentification]]
=== Exigences d'authentification

[TIP]
====
L’authentification permet de vérifier la cohérence entre l’identité d'un utilisateur et une personne physique se connectant.

A noter que les dispositifs techniques (comme les batchs) peuvent également faire l'objet d'identification et d'authentification (batch qui utilise un compte de service pour appeler une API par exemple).

L’authentification peut être à un ou plusieurs facteurs (dans ce dernier cas, on parle d’authentification forte).Ces facteurs peuvent être :

* Quelque chose que l’on *connaît* (mot de passe, pass phrase, code PIN, donné métier, …).
* Quelque chose qu’on *est* (biométrie morphologique via par exemple empreintes digitales,  reconnaissance de l'iris ou la reconnaissance faciale ; comportementales comme via la démarche ou la signature manuscrite ou génétique (analyse de l'ADN)).
* Quelque chose qu’on *possède* (devise OTP, application TOTP configurée sur son smartphone, carte à puce, pièce d’identité avec photo, clé privée sous forme de fichier, clé de récupération (PUK), …).

Penser à décrire le système d'authentification une fois inscrit mais également lors de l’inscription (authentification initiale).

Une éventuelle délégation d’authentification s’appuie sur une technologie de fédération d’identité pour authentifier l’utilisateur.

Il est bien sûr possible d’ajouter au besoin dans le tableau ci-dessous des facteurs d’authentification spécifiques à votre organisation.

====

Les facteurs d’authentification requis en fonction des situations sont (on peut exiger plusieurs occurrences du même facteur, utiliser autant de croix) :

.Exigence d'authentification par cas d'utilisation (exemple)
[cols="e,e,e,e,e,e,e"]
|====
|Cas d’authentification
|Mot de passe respectant la politique de mot de passe
|Clé publique ssh connue
|OTP par Token
|Biométrie
|Connaissance de données métier
|E-mail avec hyperlien de vérification

|Utilisateur déjà inscrit
|X|||||

|Création d’un compte
|||||XX|X

|Modification du mot de passe
|X|||||X

|Accès aux logs
||X||||

|Ajout d’un bénéficiaire de virement
|X||X|||

|Application mobile Y
||||X|||
|====

[[exigences-federation-identite]]
=== Exigences de fédération d’identité

[TIP]
====
La fédération d’identité est l’utilisation d’une même identité gérée par un identity provider (IdP) depuis plusieurs entités différentes.

Par exemple, France Connect très utilisé par les administrations et basé sur OpenId Connect permet de réutiliser le compte d’une administration pour se loguer sur le compte d’une autre (DGFiP et CNAM par exemple).

Voir aussi les « Connect with [Google|Twitter|…] » en technologie OpenId Connect.Contrairement au SSO, la fédération d'identité n’assure pas un login automatique à une application comme le SSO mais permet simplement de réutiliser les mêmes credentials (login/mot de passe).
====

====
Exemple : L’identification et l’authentification seront externalisés au fournisseur d’identité Auth0 pour simplifier la gestion de la sécurité et réduire les coûts de développement et d’exploitation.
====

[[exigences-sso-slo]]
=== Exigences de SSO et SLO

[TIP]
====
Décrire les besoin en terme de Single Sign On et Single Log Out.

Nous entendons ici SSO dans son sens le plus complet : une authentification automatique à une application d’un utilisateur déjà authentifié depuis une autre application du même domaine de confiance.

Attention, la mise en place de SSO peut être complexe, surtout si l’infrastructure (ID provider…) n’existe pas encore.

Elle nécessite souvent une adaptation des applications.

Le SSO est souvent demandé par les métiers mais cette exigence doit être justifiée.

Une application périphérique ou un outil rarement utilisé n’a en général pas besoin de SSO (une simple authentification centralisée au sein d’un annuaire peut suffire).

Attention également à évaluer l’impact qu’aurait une authentification faible (mauvais mot de passe par exemple) sur la sécurité de l’ensemble du SI.
====
====
Exemple 1 : aucun SSO n’est exigé puisque toutes les IHM de l’application sont exposées au sein d’un portail JSR352 qui gère déjà l’authentification.
====
====
Exemple 2 : aucun besoin de SSO ou SLO n’est identifié
====
====
Exemple 3 : cette application Web métier devra fournir une authentification unique mutualisée avec celle des autres applications de l’intranet : une fois authentifié sur l’une des applications, l’agent ne doit pas avoir à se reconnecter (jusqu'à expiration de sa session).De même, une déconnexion depuis l’une des applications doit assurer la déconnexion de toutes les applications de l’intranet.
====

[[exigences-non-repudiation]]
=== Exigences de non répudiation

[TIP]
====
Lister ici les actions métiers possédant une exigence de non-répudiation, c’est à dire un dispositif permettant de rendre impossible la remise en cause d’un contrat en prouvant l’identité des deux parties et l’intégrité du document par signature numérique comme décrit dans le texte n°2000-230 du 13 mars 2000 du code civil.
====

.Besoins de non-répudiation
[cols="e,e,e"]
|===
|Donnée signée|Origine du certificat client|Origine du certificat serveur

|Déclaration d’impôt sur le revenu (données X, Y et Z)
|PKI de l’administration fiscale
|Verisign
|===

[[exigences-anonymat]]
=== Exigences d'anonymat et de respect de la vie privée

[TIP]
Lister les contraintes d’anonymat et de vie privée légale (exigée par le RGPD).Voir https://www.cnil.fr/fr/rgpd-par-ou-commencer.

====
Exemple 1 : Aucune consolidation de donnée ne pourra être faite entre les données du domaine PERSONNE et du domaine SANTE.
====
====
Exemple 2 : Par soucis de confidentialité en cas d’intrusion informatique, certaines données des personnes seront expurgées avant réplication vers la zone publique : le taux de cholestérol et le poids.
====
====
Exemple 3 : aucune donnée raciale, politique, syndicales, religieuse ou d’orientation sexuelle ne pourra être stockée sous quelque forme que ce soit dans le SI.
====
====
Exemple 4 : Les données OpenData issues du domaine « logement » ne contiendront que des données consolidées de niveau commune, pas plus précise.
====
====
Exemple 5 : En application de la directive européenne « paquet telecom », un bandeau devra informer l’usager de la présence de cookies.
====
====
Exemple 6 : En application du RGPD, un consentement explicite des utilisateurs dans la conservation de leurs données personnelles de santé sera proposé.
====

[[exigences-habilitations]]
=== Exigences sur les habilitations

[TIP]
====
Une habilitation (ou autorisation) permet de donner l’accès à une fonction applicative (ou « privilège » ou « permission ») à un utilisateur ou un groupe d’utilisateur.

Exemples de fonctions : 'faire un virement inter-bancaire', 'voir l’historique de son compte', 'supprimer un utilisateur'

Attention à ne pas multiplier le nombre de fonctions et de rôles pour éviter une explosion combinatoire et des coûts de gestion associés.

Pour simplifier la gestion des habilitations par factorisation, on peut :

* Regrouper les utilisateurs dans des groupes (comme `G_chef_service`).
* Associer une liste de fonctions à un rôle (comme `R_Administrateur`, `R_banquier_niv1`, `R_chef_service`) qu’on peut affecter à une personne ou à un groupe.

Exemple de modèle classique de gestion des habilitations :

image:{resourcesDir}/roles.svg[Gestion classique des rôles]

Penser à spécifier les éventuels pseudo-utilisateurs et leurs rôles comme :

* `@anonyme` : les personnes non connectées
* `@connecte` : les personnes connectées

Préciser si l’application doit utiliser de la délégation d’autorisation (type OAuth2) et si oui, l’application est-elle fournisseur ou consommateur d’autorisations ?Quelles sont les autorisations concernées ?
====

====
Exemple 1  : les personnes non connectées auront accès à tous les privilèges en lecture seule
====
====
Exemple 2 : l’application s’appuiera sur une gestion des autorisations matricielle de type [rôles] -> [groupes ou utilisateurs] comme décrit plus bas. Le détail des autorisations sera donnée dans les SFD.
====

====
.Exemple de matrice de rôles
[cols="e,e,e,e"]
|===
|_Groupe ou utilisateur_|_Rôle_ `suppression`|_Rôle_ `administration`|_Rôle `_consultation données de base`

|Groupe `g_usagers`
|
|
|X

|Groupe `@anonyme`
|
|
|

|Groupe `g_admin`
|X
|X
|X

|Utilisateur `xyz`
|X
|
|X
|===

====

[[exigences-tracabilite]]
=== Exigences de traçabilité et d'auditabilité

[TIP]
====
Lister ici les besoins en traces permettant de détecter par exemple :

* Un usage abusif des applications Back Office par des employés
* Des intrusions informatiques
* Des modifications de données

Les traces sont des données nominatives et complètes pour permettre l’audit.Elles sont donc elles-mêmes sensibles et nécessitent souvent un bon niveau de confidentialité.

Différentier :

* Les traces métier (bilan d’un acte de gestion complet comme `l’agent X a consulté le dossier de Mme Y`) ;
* … et les traces applicatives (logs) comme dans un fichier de log : `[INFO] 2016/12/23 11:14 [Agent X] Appel du service consulter` qui sont de niveau technique.

Pour les données les plus sensibles, il est possible de prévoir une traçabilité à deux niveaux (tracer la consultation des traces) pour éviter une traçabilité hiérarchique abusive.

La traçabilité des données des référentiels (base des personnes typiquement) nécessite une historisation complète, ce qui est de toute façon une bonne pratique d'urbanisation (voir par exemple Longépé « Le projet d’Urbanisation du SI », règles applicatives 1, 2 et 3).

Pour cela, prévoir un MCD permettant d’ajouter un enregistrement à chaque changement de la donnée avec une date de modification et une date d’effet.
====

====
Exemple 1 : pour le module X, toute action métier (en mise à jour comme en consultation) devra faire l’objet d’une trace métier contenant a minima l’agent, la date et en cas de modification l’ancienne et la nouvelle valeur.
====
====
Exemple 2 : Toute intrusion dans le SI devra être détectée (dans la mesure du possible).
====
====
Exemple 3 : nous devons pouvoir reconstituer l’historique du dossier de tout patient à n’importe quelle date.
====

.Données à conserver pour preuves
[cols="e,e,e"]
|===
|Donnée|Objectif|Durée de rétention

|Log complet (IP, heure GMT, détail) des commandes passées sur le site
|Prouver que la commande a bien été passée
|1 an

|Date et contenu du mail de confirmation
|Prouver que le mail de confirmation a bien été envoyé
|2 ans

|Contrat d’assurance signé et numérisé en PDF
|Prouver que le contrat a bien été signé
|5 ans

|Avis d’imposition primitif avec signature numérique
|Conserver le montant et de l’impôt.
|5 ans
|===

== Mesures de sécurité

=== Intégrité

Dispositifs répondant aux <<exigences-integrite,exigences d'intégrité>> :

.Mesures pour assurer le niveau d'intégrité demandée
[cols="e,e,e"]
|===
|Classe de données|Niveau exigé|Mesures

|Données de la base métier
|Intègre
a|
* Utilisation du SGBDR PostgreSQL avec un niveau d’isolation transactionnelle SERIALIZABLE
* Les entités seront référencées uniquement par des ID techniques issues de séquences PostgreSQL

|Données archivées
|Détecté
|Génération de checksums SHA-256 des backups

|Données calculées D1
|Maîtrisé
|Stockage d’un checksum SHA1, relance du calcul automatiquement par batch dans les 24H.

|Silo NoSQL des données Big Data avant consolidation
|Non intègre
|Pas de mesure particulière, pas de backup

|Sources
|Intègre
|Utilisation du SCM Git

|Avis d’imposition PDF
|Intègre
|Signature numérique du montant net + date + nom au format PKCS#7 (RSA, SHA256) avec horodatage. La signature résultante sera intégrée a posteriori au format hexadécimal en pied de page du PDF.
|===

=== Confidentialité

Dispositifs répondant aux <<exigences-confidentialite,exigences de confidentialité>> :

.Mesures pour assurer le niveau de confidentialité demandé
[cols="e,e,e"]
|===
|Classe de données|Niveau exigé|Mesures

|Contenu éditorial
|Public
|Échanges en HTTPS, pas d’authentification

|Profil du compte du site Web
|Limité
|L’accès à ce contenu nécessite une authentification réussie par login/mot de passe

|Historique du compte
|Réservé
|L’accès à ce contenu est réservé aux exploitants habilités, uniquement via des requêtes PL/SQL de la base de données

|Logs des activités de l’internaute
|Réservé
|L’accès aux fichiers de log est réservé aux exploitants habilités (accès SSH à la machine M et mot de passe Unix)

|Données RH aides sociales aux employés
|Privé
|Ces données sont chiffrées en AES 256 sous forme d’un BLOB en base, remontées au client Web via le service REST Y puis déchiffrées au sein du navigateur dans l’application Angular (librairie forge.js) via un mot de passe complémentaire de l’utilisateur (non stocké coté serveur). +
Il s’agit donc d’un chiffrement client uniquement. Une perte de mot de passe rend les données irrécupérables. Les données modifiées sur le client sont chiffrées et enregistrées à nouveau dans le BLOB via le service REST X.
|===

[TIP]
====
Penser aussi à la confidentialité des données dérivées :

* chiffrement des backups ;
* chiffrement des données clientes pour les applications lourdes. Cela peut être un chiffrement matériel en SED (Self Encryption Disk), un chiffrement logiciel de niveau partition (SafeGuard, dm-crypt) ou de niveau fichier (encfs, TrueCrypt…)
====

=== Identification

Dispositifs répondant aux <<exigences-identification,exigences d'identification>> :

_Exemple 1  : L’Id des usagers de l’application sera l’attribut uid des DN `cn=XXX,ou=service1,dc=entreprise,dc=com` dans l’annuaire LDAP central. Un filtre sera également appliqué sur l’appartenance au groupe `ou=monapplication,dc=entreprise,dc=com`._

_Exemple 2  : Pour assurer la non réutilisation des ID des comptes supprimés, une table d’historique sera ajoutée dans l’application et requêtée avant toute création de nouveau compte._

=== Authentification

Dispositifs répondant aux <<exigences-authentification,exigences d'authentification>> :
[TIP]
====
Pour les authentifications par mot de passe, décrire le mode de stockage et de vérification. Penser également à décrire les solutions de changement de mot de passe.
====
====
Exemple 1 : L’authentification des internautes inscrits se fera par login/mot de passe (respectant la politique de mot de passe P)
====
====
Exemple 2 : L’authentification des internautes à l’inscription se fera par la saisie du code internaute figurant sur les factures + la valeur de la dernière facture puis par l’activation du compte via un lien figurant dans un e-mail de vérification.
====
====
Exemple 3 : lors de la création d’un nouveau bénéficiaire de virement dans l’espace internet, l’utilisateur devra fournir un mot de passe unique issu de son token OTP en plus d’être authentifié.
====
====
Exemple 4 : Les mots de passe ne seront en aucun cas conservés mais stockés sous la forme de digest bcrypt.
====


=== Fédération d’identité

Dispositifs répondant aux <<exigences-federation-identite,exigences de fédération d’identité>> :

[TIP]
====
Les solutions les plus courantes sont actuellement : OpenId Connect (OIDC), SAML ou Oauth 2.0 (pseudo-authentification seulement pour cette dernière).

Pour les applications Web, préciser les contraintes navigateur (activation des cookies en particulier).
====

====
Exemple  : L’IHM grand public permettra une identification et authentification France Connect (basé sur OIDC) de sorte que les utilisateurs puissent utiliser leur compte DGFiP ou CNAM pour s’identifier et s’authentifier. La cinématique d’authentification sera la suivante : <faire un schéma>
====


=== SSO, SLO

Dispositifs répondant aux <<exigences-sso-slo,exigences de SSO et SLO>> :
[TIP]
====
Détailler la technologie choisie et son intégration. Quelques solutions courantes : CAS, OpenAM, LemonLDAP::NG. Pour les applications Web, préciser les contraintes navigateur (activation des cookies en particulier).
====
====
Exemple 1 : L’IHM X intégrera un client CAS spring-security pour le SSO. Le serveur CAS utilisé sera YYY. Son royaume d'authentification (realm) sera l’annuaire AD Y.
====
====
Exemple 2 : Comme toutes les applications du portail métier, l’IHM X devra gérer les callbacks de déconnexion provenant du serveur CAS suite à une demande de SLO.
====

=== Comptes de service

[TIP]
====
Les comptes de service sont utilisés pour l'authentification à un composant technique depuis un batch ou une API.
====

.Comptes de service
[cols='1,2,2']
|====
|Compte | Ressource requérant authentification | mode de stockage des credentials

|Comptes JDBC (un compte par base de données) | Instances PG et SqlServer.
| Stockage en clair dans la configuration des datasources. Valorisé à partir des pilars Salt des API.
|====


=== Non-répudiation et horodatage

Dispositifs répondant aux <<exigences-non-repudiation,exigences de non répudiation>> :

====
Exemple : La déclaration d’impôt sera signée par le certificat client de l’usager (certificat X509, RSA, SHA-256) qui lui a été fourni par le composant X.
====

[TIP]
====
Les solutions d'horodatage cryptographiques ne répondent pas à un besoin propre mais sont souvent requis pour répondre à des besoins de non répudiation (spécialement via des jetons d'horodatage utilisés conjointement avec une signature électronique afin de prévenir d'antidatage ou le postdatage).

====
Exemple : Les signatures électroniques seront accompagnées d'un jeton d'horodatage qualifié eIDAS délivrés par le prestataire de service de confiance XYZ.
====
====

=== Anonymat et vie privée

Dispositifs répondant aux <<exigences-anonymat,exigences d'anonymat et de respect de la vie privée>> :

====
Exemple 1 : un audit interne sera mené une fois par an sur le contenu des données en base et les extractions à destination des partenaires.
====
====
Exemple 2 : les données à destination de la zone publique seront exportées partiellement via un `COPY (SELECT …) TO <fichier>`. Les colonnes sensibles seront ainsi exclues de la réplication.
====
====
Exemple 3 : le bandeau d’acceptation des cookies sera mis en ouvre sur toutes les pages de l’application Angular via le module `angular-cookie-law`.
====

=== Habilitations

Dispositifs répondant aux <<exigences-habilitations,exigences sur les habilitations>> :
====
Exemple 1 : la gestion des autorisations sera gérée applicativement et stockée dans la base applicative PostgreSQL. Ces tables seront décrites dans le dossier de spécification.
====
====
Exemple 2 : L’obtention du carnet d’adresse Facebook sera en OAuth2. On utilisera l’API Java Google Oauth2.
====

=== Tracabilité, auditabilité

Dispositifs répondant aux <<exigences-tracabilite,exigences de traçabilité et d'auditabilité>> :

====
Exemple 1 : à la fin de chaque action métier, l’application ReactJS appellera dans une action asynchrone un service REST de trace métier. Ce service stockera les traces dans une base Elastic Search pour consultation en Kibana.
====
====
Exemple 2 : l’outil d’IDS hybride (réseau + host) OSSEC sera installé sur l’ensemble des machines utilisées par l’application.
====
====
Exemple 3 : Les  tables X, Y, .. seront historisées suivant le principe suivant : … <diagramme de classe>
====
====
Exemple 4 : tous les documents servant de preuve seront archivés dans la GED.
====
====
Exemple 5 : Les logs contenant le tag `[PREUVE]` et issu de l’ensemble des composants seront centralisés via le système de centralisation de log Elastic Search puis insérés avec traitement Logstash de façon journalière vers l'index Elastic `preuves`.
====

=== Lutte contre les cybermenaces
Ces dispositifs techniques ou organisationnels permettent de lutter contre les cybermenaces, comme les malwares, le phishing, les attaques DOS/DDOS, l'exploitation de vulnérabilités (connues ou zero-day), l'ingénierie sociale, les escroqueries en ligne, les fuites de données sensibles, etc. La plupart des solutions sont mises en œuvre au niveau du Système d'Information (SI). Il s'agit donc probablement ici de pointer vers les documents de référence et de détailler les éventuelles solutions spécifiques à votre projet ou produit.

==== Solutions de prévention

Incluent :

* Les formations et sensibilisations des utilisateurs.
* Les formations et sensibilisations des acteurs informatiques.
* La mise en place d'un système de prévention d'intrusion (IPS) qui bloque les acteurs jugés malicieux.
* La mise en place et le respect des procédures, comme les revues régulières d'habilitations.
* Le durcissement des règles de sécurité comme imposer l'authentification à facteurs multiples obligatoires, le renouvellement obligatoire des mots de passe ou l'utilisation de coffres-fort numériques (personnels ou partagés) pour stocker les secrets.
* La réalisation régulière d'audits (tests de pénétration et/ou audit de code) si possible par des experts externes.
* Les outils de prévention de la perte de données (DLP) qui analysent notamment les flux réseau ou les emails à la recherche de fuites de données sensibles ou de propriété intellectuelle.
* Le blocage de certains systèmes vecteurs d'attaques comme les clés USB.
* Les systèmes de mises à jour automatiques des patches de sécurité sur les systèmes d'exploitation.

====
Exemple 1 : Sensibilisation des utilisateurs via https://cyber.gouv.fr/bonnes-pratiques-protegez-vous[ces recommendations de l'ANSSI].
====

====
Exemple 2 : Sensibilisation au risque auprès des acteurs informatiques via https://cyber.gouv.fr/guides-essentiels-et-bonnes-pratiques-de-cybersecurite-par-ou-commencer[les guides essentiels de l'ANSSI].
====

====
Exemple 3 : Mise en place de l'IPS OpenSource CrowdSec basé sur le partage d'information communautaire (Crowdsourcing).
====


==== Solutions de détection

Incluent :

* Les antivirus (dont les dernières générations incluent de l'IA et vont au-delà de la recherche de signatures).
* Les WAF (Web Application Firewall) qui détectent et bloquent les tentatives d'attaques en temps réel.
* Les outils de SIEM (Security Information and Event Management) qui analysent les logs issus de sources variées.
* Les outils d'IDS (Intrusion Detection System), assurant souvent également la fonction d'IPS et analysant les flux réseau à la recherche de tentatives d'accès malicieux (comme des tentatives d'exploitation de CVE).
* Les outils SAST (Static Application Security Testing) et DAST (Dynamic Application Security Testing) analysant respectivement le code source de l'organisation et le comportement à l'exécution, à la recherche de vulnérabilités connues.
* Les outils SCA (Software Composition Analysis) analysant les dépendances (essentiellement Open Source) des projets et remontant la liste des CVE (vulnérabilités connues) dès que possible en vue de les mettre à jour.

====
Exemple 1 : Mise en place au sein des pipelines de CI/CD de l'outil SCA OWASP Dependency-Check permettant de détecter les librairies Open Source contenant des vulnérabilités (CVE). Toute présence de CVE doit être bloquante.
====

==== Solutions de correction

Incluent :

* Les solutions anti-malware qui suppriment les logiciels malveillants.
* Les outils de restauration de sauvegardes (la connaissance du MTTR, défini dans la vue infrastructure, est cruciale pour la planification de la restauration).
* Les outils et procédures permettant l'isolation de composants ou de zones compromises au sein du SI.
* Les outils de gestion de parc logiciel qui bloquent les logiciels non autorisés.
* Les outils et méthodologies d'analyse forensique permettant d'analyser les logs pour comprendre les chemins d'une attaque et construire un post-mortem.
* Les procédures et outils de réponse à une attaque.

====
Exemple 1 : Préparation de procédures et d'un https://www.cybermalveillance.gouv.fr/tous-nos-contenus/bonnes-pratiques/cyberattaque-que-faire-guide-dirigeants[plan de secours] en cas d'incident de sécurité suivant le standard NIST SP 800-61.
====

==== Solutions de prédiction

Ces solutions récentes sont essentiellement basées sur du Machine Learning et l'analyse de données en masse (Big Data). Elles incluent :

* Les solutions de type User and Entity Behavior Analytics (UEBA) qui permettent de détecter les comportements anormaux de certains utilisateurs.
* Les outils de simulations d'attaques complexes ;
* Les outils et référentiels de renseignement sur les menaces (Threat Intelligence).

====
Exemple 1 : Analyse et alerting des comportements suspects avec AWS GuardDuty sur une application cloud déployée sur AWS.
====

====
Exemple 2 : Utilisation de CrowdSec Threat Intelligence pour découvrir les tendances des menaces basées sur des données réelles et consolidées.
====


== RACI

[NOTE]
====
Ce RACI permet de définir clairement les rôles de chacun concernant les actes liés à la sécurité.

:r: pass:quotes[[.green]#R#]
:a: pass:quotes[[.red]#A#]
:c: pass:quotes[[.blue]#C#]
:i: pass:quotes[[.orange]#I#]
:na: pass:quotes[[.grey]#N/A#]
:et: pass:quotes[[.grey]#&amp;#]

* {r} : *Responsible* (personne qui va exécuter : elle en est responsable)
* {a} : *Accountable* (personne qui va approuver la tâche : elle en est l'autorité)
* {c} : *Consulted* (personne qui va être consultée dans l'exécution de la tâche)
* {i} : *Informed* (personne qui sera informée lorsque la tâche est terminée)
====

=== Gestion de la plateforme AWS (exemple)

.Gestion de la plateforme AWS
[cols="6,^1,^1,^1"]
|===
||Équipe Systèmes & Cloud|Équipe Sécurité SI|Équipe Réseau

.^|Création des accounts AWS
.^|{r} {et} {a}
.^|{c} {et} {i}
.^|{a}

.^|Création des SCP AWS
.^|{r} {et} {a}
.^|{c} {et} {i}
.^|{a}
|===

=== Gestion des comptes applicatifs (exemple)

.Gestion des comptes applicatifs
[cols="6,^1,^1,^1"]
|===
||Équipe annuaire|Équipe projet|Équipe SOC

.^|Création des comptes SSO
.^|{r} {et} {a}
.^|{i}
.^|{i}

.^|Gestion des habilitations
.^|{i}
.^|{r} {et} {a}
.^|{i}

.^|Revue d'habilitations annuelle
.^|{c} {et} {i}
.^|{i}
.^|{r} {et} {a}

|===

== Auto-contrôles

=== Auto-contrôle des vulnérabilités

[TIP]
====
La gestion des vulnérabilités dépasse largement le cadre de ce document mais il est bon de s’auto-contrôler pour s’assurer que les failles les plus courantes sont bien prises en compte et comment. Cette liste est en partie basée sur le https://owasp.org/Top10/[TOP 10 OWASP].

Bien entendu, il existe de nombreux autres points de contrôle dépendants du contexte de l’application
====

.Checklist d'auto-contrôle de prise en compte des vulnérabilités courantes
[cols="e,e,3e"]
|===
|Vulnérabilité
|Prise en compte ?
|Mesures techniques entreprises

|Accès à des ports privés
|X
|Configuration du pare-feu iptables sur la machine exposée à Internet. Seul les ports 80 et 443 sont ouverts. Le pare-feu sera configuré en mode stateful (avec extension conntrack)

|Attaque de mot de passe par force brute
|X
|Utilisation de fail2ban, mise en prison de 1h au bout de 3 tentatives de connexion ssh.

|Visibilité des URLs directes
|X
|Centralisation de tous les accès depuis Internet via un reverse proxy Apache + mod_proxy. Réécriture d’URLs pour masquer les URL internes.

|Contournement du contrôle d’accès
|X
|Utilisation du SSO CAS, voir chapitre 3

|Injection SQL
|X
|Utilisation de PreparedStatement uniquement, audit des requêtes SQL.

|Injection NoSQL
|X
|Désactivation du suport JS par MongoDB

|Injection OS
|X
|Vérification qu’il n’y a aucun appel de commandes systèmes dans le code (type Runtime.exec() )

|Violation de gestion d’authentification et de session
|X
|Traité avec le dispositif anti-CSRF, voir plus bas. On logue l’IP à fin d’audit.

|XSS
|X
a|
* _Utilisation de librairie d’échappement. Pour les modules Java, nous utiliserons StringEscapeUtils.escapeHtml4() de commons-lang_
* __Utilisation des headers HTTP : X-Frame-Options SAMEORIGIN, Content-Security-Policy__
* __Spécification systématique de l’encoding dans le header de réponse Content-Type (ex : text/html;charset=UTF-8) pour parer les attaques basées sur des caractères spéciaux contournant l'anti-XSS__

|ReDOS
|X
|Vérification que les expressions régulières utilisées par les dispositifs anti-XSS ne sont pas éligibles à ce type d’attaque, voir https://www.owasp.org/index.php/Regular_expression_Denial_of_Service_-_ReDoS

|Référence directe à un objet
|X
|Vérification à chaque requête que les arguments passés correspondent bien à la personne identifiée. Par exemple, toute requête contient son ID et on vérifie par une requête que le dossier qu’elle tente de consulter lui appartient bien avant de poursuivre la requête initiale.

|Planification des mises à jour de sécurité
|X
a|
* __Les mises à jour Centos seront planifiées tous les premiers mercredi du mois__
* __Les mises à jour Wildfly sont appliquées au plus deux semaines après leur sortie__

|Exposition de données sensibles
|X
a|
* __Tous les algorithmes de sécurité sont à jour : au minimum SHA-256, AES 256__
* __Le SSL V2 et V3 est désactivé coté Apache suite à la faille DROWN ( SSLProtocol all -SSLv2 -SSLv3)__
* __L’application ne fonctionne qu’en HTTPS__
* __Le serveur Web fixera le header HSTS avec includeSubDomains sur toutes les ressources__

|CSRF
|X
|Utilisation du dispositif anti-CSRF d’AngularJS (https://docs.angularjs.org/api/ng/service/$http )

|Manque de contrôle d’accès au niveau fonctionnel
|X
a|
* __Mise en place de la politique d’autorisation décrite au chapitre 2__
* __Campagne de tests fonctionnels__

|Log injection
|X
a|
* __Échappement des logs avant de les transmettre à log4j__
* __Vérification des outils de consultation de logs__

|Attaques HTTPS + compression CRIME/BREACH
|X
a|
* __Désactivation de la compression HTTPS au niveau de l’Apache : SSLCompression off __
* __Dispositif anti-CSRF__

|Upload de fichiers malicieux
|X
| Validation des pièces jointes par l'anti-virus ClamAV

|===

=== Auto-contrôle RGPD

[TIP]
====
Cette section aide à vérifier la prise en compte des exigences du https://www.cnil.fr/fr/rgpd-par-ou-commencer[RGPD].

A noter que le RGPD ne concerne que les personnes physiques, pas les personnes morales.

Cette liste n'est qu'un exemple partiel, faire valider votre projet par votre service sécurité et juridique.
====

.Checklist d'auto-contrôle de respect du RGPD
[cols="e,e,e"]
|===
|Exigence RGPD
|Prise en compte ?
|Mesures techniques entreprises

|Registre du traitement de données personnelles
|X
|Liste des traitements et données personnelles dans le document XYZ

|Pas de données personnelles inutiles
|X
|Vérifié, la rétention de numéro de CB a été supprimée car inutile.

|Droits des personnes (information, accès, rectification, opposition, effacement, portabilité et limitation du traitement.)
|X
|Oui, traitement manuel sur demande depuis le formulaire situé à http://xyz, traitement en 1 mois max

|Sécurisation des données
|X
|Oui, voir les mesures listées dans ce document notamment sur la confidentialité, audibilité et intégrité.
|===

:leveloffset!:

[#glossaire]
:leveloffset: +1


[glosary]
= Glossaire des termes utilisés

WARNING: Merci de respecter l'ordre alphabétique lors des éditions du document

[cols="1,4,4"]
|=======================================================================
|Terme |Signification | Commentaire
|Bibliothèque|Un ensemble de fonctions utilitaires, regroupées et mises à disposition afin de pouvoir être utilisées sans avoir à les réécrire.|

|=======================================================================


:leveloffset!:

[#annexe-A]
:leveloffset: +1


[appendix]
= Clean Code

== Introduction

Code is clean if it can be understood easily – by everyone on the team.
Clean code can be read and enhanced by a developer other than its original author.
With understandability comes readability, changeability, extensibility and maintainability.

== General rules

1. Follow standard conventions.
2. Keep it simple stupid.
Simpler is always better.
Reduce complexity as much as possible.
3. Boy scout rule.
Leave the campground cleaner than you found it.
4. Always find root cause.
Always look for the root cause of a problem.

== Design rules

1. Keep configurable data at high levels.
2. Prefer polymorphism to if/else or switch/case.
3. Separate multi-threading code.
4. Prevent over-configurability.
5. Use dependency injection.
6. Follow Law of Demeter.
A class should know only its direct dependencies.

== Understandability tips

1. Be consistent.
If you do something a certain way, do all similar things in the same way.
2. Use explanatory variables.
3. Encapsulate boundary conditions.
Boundary conditions are hard to keep track of.
Put the processing for them in one place.
4. Prefer dedicated value objects to primitive type.
5. Avoid logical dependency.
Don't write methods which works correctly depending on something else in the same class.
6. Avoid negative conditionals.

== Names rules

1. Choose descriptive and unambiguous names.
2. Make meaningful distinction.
3. Use pronounceable names.
4. Use searchable names.
5. Replace magic numbers with named constants.
6. Avoid encodings.
Don't append prefixes or type information.

== Functions rules

1. Small.
2. Do one thing.
3. Use descriptive names.
4. Prefer fewer arguments.
5. Have no side effects.
6. Don't use flag arguments.
Split method into several independent methods that can be called from the client without the flag.

== Comments rules

1. Always try to explain yourself in code.
2. Don't be redundant.
3. Don't add obvious noise.
4. Don't use closing brace comments.
5. Don't comment out code.
Just remove.
6. Use as explanation of intent.
7. Use as clarification of code.
8. Use as warning of consequences.

== Source code structure

1. Separate concepts vertically.
2. Related code should appear vertically dense.
3. Declare variables close to their usage.
4. Dependent functions should be close.
5. Similar functions should be close.
6. Place functions in the downward direction.
7. Keep lines short.
8. Don't use horizontal alignment.
9. Use white space to associate related things and disassociate weakly related.
10. Don't break indentation.

== Objects and data structures

1. Hide internal structure.
2. Prefer data structures.
3. Avoid hybrids structures (half object and half data).
4. Should be small.
5. Do one thing.
6. Small number of instance variables.
7. Base class should know nothing about their derivatives.
8. Better to have many functions than to pass some code into a function to select a behavior.
9. Prefer non-static methods to static methods.

== Tests

1. One assert per test.
2. Readable.
3. Fast.
4. Independent.
5. Repeatable.

== Code smells

1. Rigidity.
The software is difficult to change.
A small change causes a cascade of subsequent changes.
2. Fragility.
The software breaks in many places due to a single change.
3. Immobility.
You cannot reuse parts of the code in other projects because of involved risks and high effort.
4. Needless Complexity.
5. Needless Repetition.
6. Opacity.
The code is hard to understand.

:leveloffset!:
[#annexe-B]
:leveloffset: +1


[appendix]
= TDD

== Introduction

This document shows the Test-driven development.

== Test-driven development cycle

* **Add a test**
** The adding of a new feature begins by writing a test that passes iff the feature's specifications are met.
The developer can discover these specifications by asking about use cases and user stories.
A key benefit of test-driven development is that it makes the developer focus on requirements before writing code.
This is in contrast with the usual practice, where unit tests are only written after code.

* **Run all tests The new test should fail for expected reasons**

** This shows that new code is actually needed for the desired feature.
It validates that the test harness is working correctly.
It rules out the possibility that the new test is flawed and will always pass.

* **Write the simplest code that passes the new test**

** Inelegant or hard code is acceptable, as long as it passes the test.
The code will be honed anyway in Step 5. No code should be added beyond the tested functionality.

* **All tests should now pass**

** If any fail, the new code must be revised until they pass.
This ensures the new code meets the test requirements and does not break existing features.

* **Refactor as needed, using tests after each refactor to ensure that functionality is preserved**

** Code is refactored for readability and maintainability.
In particular, hard-coded test data should be removed.
Running the test suite after each refactor helps ensure that no existing functionality is broken.


*** Examples of refactoring:

**** moving code to where it most logically belongs
**** removing duplicate code
**** making names self-documenting
**** splitting methods into smaller pieces
**** re-arranging inheritance hierarchies

* **Repeat**

** The cycle above is repeated for each new piece of functionality.
Tests should be small and incremental, and commits made often.
That way, if new code fails some tests, the programmer can simply undo or revert rather than debug excessively.
When using external libraries, it is important not to write tests that are so small as to effectively test merely the library itself, unless there is some reason to believe that the library is buggy or not feature-rich enough to serve all the needs of the software under development.

== Best practices

=== Test structure

Effective layout of a test case ensures all required actions are completed, improves the readability of the test case, and smooths the flow of execution.
Consistent structure helps in building a self-documenting test case.
A commonly applied structure for test cases has (1) setup, (2) execution, (3) validation, and (4) cleanup.

* Setup: Put the Unit Under Test (UUT) or the overall test system in the state needed to run the test.
* Execution: Trigger/drive the UUT to perform the target behavior and capture all output, such as return values and output parameters.
This step is usually very simple.
* Validation: Ensure the results of the test are correct.
These results may include explicit outputs captured during execution or state changes in the UUT.
* Cleanup: Restore the UUT or the overall test system to the pre-test state.
This restoration permits another test to execute immediately after this one.
In some cases in order to preserve the information for possible test failure analysis the cleanup should be starting the test just before the test's setup run.

=== Individual best practices

Some best practices that an individual could follow would be to separate common set-up and tear-down logic into test support services utilized by the appropriate test cases, to keep each test oracle focused on only the results necessary to validate its test, and to design time-related tests to allow tolerance for execution in non-real time operating systems.
The common practice of allowing a 5-10 percent margin for late execution reduces the potential number of false negatives in test execution.
It is also suggested to treat test code with the same respect as production code.
Test code must work correctly for both positive and negative cases, last a long time, and be readable and maintainable.
Teams can get together with and review tests and test practices to share effective techniques and catch bad habits.

=== Practices to avoid, or "anti-patterns"

* Having test cases depend on system state manipulated from previously executed test cases (i.e., you should always start a unit test from a known and pre-configured state).
* Dependencies between test cases.
A test suite where test cases are dependent upon each other is brittle and complex.
Execution order should not be presumed.
Basic refactoring of the initial test cases or structure of the UUT causes a spiral of increasingly pervasive impacts in associated tests.
* Interdependent tests.
Interdependent tests can cause cascading false negatives.
A failure in an early test case breaks a later test case even if no actual fault exists in the UUT, increasing defect analysis and debug efforts.
* Testing precise execution behavior timing or performance.
* Building "all-knowing oracles".
An oracle that inspects more than necessary is more expensive and brittle over time.
This very common error is dangerous because it causes a subtle but pervasive time sink across the complex project.[9]
* Testing implementation details.
* Slow running tests.

:leveloffset!:
[#annexe-C]
:leveloffset: +1


[appendix]
= Best Practices Angular

== Introduction

This document show a few best practices with angular.

== Generale Rules

- Per file, the code must not exceed from 400 lines limit
- Per function, the code must not exceed from 75 lines
- If the values of the variables are intact, declare it with const
- Names of properties and methods should be in lower camel case
- We shouldn’t name our interfaces with the starting capital I letter as we do in some programming languages.
- Breaking down Components : This might be an extension of the single responsibility principle not just to the code files or the methods, but to components as well.
The larger the component is, the harder it becomes to debug, maintain and test.
- Using Interfaces
- Safe Navigation Operator (?) : To be on the safe side we should always use the safe navigation operator while accessing a property from an object in a component’s template.
If the object is null and we try to access a property, we are going to get an exception.
But if we use the save navigation (?) operator, the template will ignore the null value and will access the property once the object is not null anymore.
- Prevent Memory Leaks in Angular Observable : Observable memory leaks are very common and found in every programming language, library, or framework.
Angular is no exception to that.
Observables in Angular are very useful as it streamlines your data, but memory leak is one of the very serious issues that might occur if you are not focused.
It can create the worst situation in mid of development.
Here’re some of the tips which follow to avoid leaks.
* Using async pipe
* Using take(1)
* Using takeUntil()
- Using index.ts : index.ts helps us to keep all related things together so that we don’t have to be bothered about the source file name.
This helps reduce the size of the import statement.
- Change Detection Optimisations :
* Use NgIf and not CSS - If DOM elements aren’t visible, instead of hiding them with CSS, it's a good practice to remove them from the DOM by using *ngIf.
* Move complex calculations into the ngDoCheck lifecycle hook to make your expressions faster.
* Cache complex calculations as long as possible
* Use the OnPush change detection strategy to tell Angular there have been no changes.
This lets you skip the entire change detection step.
- Build Reusable Components : If there is a piece of UI that you need in many places in your application, build a component out of it and use the component.
This will save you a lot of trouble if, for some reason, the UI has to be changed.
In that case, you do not go around changing the UI code in all the places.
Instead, you can change the code in the component and that is it.
- Using trackBy in NgFor : When using ngFor to loop over an array in templates, use it with a trackBy function which will return a unique identifier for each DOM item.
When an array changes, Angular re-renders the whole DOM tree.
But when you use trackBy, Angular will know which element has changed and will only make DOM changes only for that element.
- Using Smart - Dumb components : This pattern helps to use OnPush change detection strategy to tell Angular there have been no changes in the dumb components.
Smart components are used in manipulating data, calling the APIs, focussing more on functionalities, and managing states.
While dumb components are all about cosmetics, they focus more on how they look.
- Using strict types instead of "any" : While working on an Angular project, developers, generally end up typing ‘any’ to declare variables.
If you are not specifying the variables and constants, they will be assumed by the value and as a result, will be assigned to it.
If it happens, you are now in trouble as it will create some unintended issues, anytime.

:leveloffset!:
